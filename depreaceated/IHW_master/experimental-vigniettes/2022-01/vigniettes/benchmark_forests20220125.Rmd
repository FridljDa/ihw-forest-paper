---
title: "Boca Leek IHW Benchmark"
output: html_document
---

## Preperation
First some cleaning and basic packages.
```{r setup, message = F}
library(magrittr)
library(dplyr)
knitr::opts_chunk$set(echo = TRUE)

library(doParallel)
n.cores <- parallel::detectCores()
doParallel::registerDoParallel(cores = min(5, n.cores - 1))
library(doRNG)
set.seed(123)
```

Now we need to download my current version of IHW. Make sure the official IHW package is not loaded. In doubt, detach IHW before. Make sure you have the most current version of `remotes`.
```{r load_functions, eval = T}
# remotes::install_github("FridljDa/IHW", subdir = "bioconductor")
# summaryDir <- "/g/huber/users/fridljand/R/HIGH/data/14_summary"
# censDir <- "/Volumes/fridljand/R/HIGH/data/05_demog"
# devtools::install_github("Huber-group-EMBL/covariate-powered-cross-weighted-multiple-testing", subdir = "IHWStatsPaper")
# devtools::load_all("/Users/default/Google Drive/currentDocumants/Studium/Master/3.Semester/Masterarbeit/IHW")#
# devtools::load_all("/Users/default/Google Drive/currentDocumants/Studium/Master/3.Semester/Masterarbeit/RFCDE")
devtools::load_all("IHW") #
devtools::load_all("RFCDE")
library("IHW")
# library("RFCDE")
```

This will be the function to evaluate the IHW results. We want to control the False Discovery Rate (FDR) at a prespecified level, typically 0.1. We want to maximize power, e.g. number of discoveries.
```{r create_fdp_eval}
fdp_eval <- function(IHW_results, Hs) {
  # evaluating all Monte Carlo replicates
  fdp_compare_r <- mapply(function(IHW_results_i, Hs_i) {
    rjs <- IHW::rejected_hypotheses(IHW_results_i)
    rjs_total <- sum(rjs)
    pow <- sum(rjs * Hs_i) / max(1, sum(Hs_i))
    FDP <- sum(rjs * (1 - Hs_i)) / max(1, rjs_total)
    data.frame(rjs = rjs_total, pow = pow, FDP = FDP)
  }, IHW_results, Hs)

  fdp_compare_r <- as.data.frame(t(fdp_compare_r))

  # taking the average
  fdp_compare_r <- fdp_compare_r %>%
    dplyr::summarise(
      rjs = mean(as.numeric(rjs)),
      pow = mean(as.numeric(pow)), # this should be maximized
      FDR = mean(as.numeric(FDP)) # this should be controlled at a pre-specified level alpha
    )
  return(fdp_compare_r)
}
```

Setting some parameters used throughout. 
```{r set_parameters}
m <- 10000
r <- 10 # number of monte carlo replicates, increases run time immensely!
alpha <- .1
```

The following parameters are auto-set in the BioConductor implementation. My code is not capable of this yet. 
```{r set_parameters2}
nfolds <- 3
folds <- sample(1:nfolds, m, replace = TRUE)
lambda <- Inf
```

For the random forest approach, a censoring parameter `tau` is introduced. I will revisit auto setting later. `ntrees` controls the number of trees in each random forest.
```{r set_parameters3}
tau <- 0.7 # censoring parameter for BocaLeek estimator
ntrees <- 100 # number of trees per forest
```

## 0. grouped Simulation with signal
```{r}
group_sim_combs <- expand.grid(
  m = m,
  K_coarse = c(2, 5, 10, 20, 40),
  pi0_global = 0.9,
  seed = seq_len(r)
)

group_sim <- foreach(i = 1:nrow(group_sim_combs)) %dorng% {
  IHWStatsPaper::grouped_sim(
    m = group_sim_combs$m[i],
    K_coarse = group_sim_combs$K[i],
    pi0_global = group_sim_combs$pi0_global[i],
    sparsity_multiplier = 4
  )
}
```

```{r}
ihw_grouped_sim_forest <- foreach(group_sim_i = group_sim) %dopar% {
  Ps_i <- group_sim_i$Ps
  Xs_i <- group_sim_i$Xs
  ihw_grouped_sim_forest <- ihw(Ps_i, Xs_i, alpha = alpha, folds = folds, strat = "RFCDE", ntrees = ntrees, tau = tau, lambda = lambda)
}
```

```{r}
evaluated_grouped_sim_forest <- foreach(i = 1:nrow(group_sim_combs)) %dorng% {
  ihw_grouped_sim_forest_i <- ihw_grouped_sim_forest[[i]]
  evaluated_grouped_sim_forest_i <- IHWStatsPaper::fdp_eval( Hs = group_sim[[i]]$Hs, rjs =IHW::rejected_hypotheses(ihw_grouped_sim_forest_i))
  dplyr::mutate(evaluated_grouped_sim_forest_i,
    m = group_sim_combs$m[i],
    K_coarse = group_sim_combs$K[i],
    pi0_global = group_sim_combs$pi0_global[i],
    seed = group_sim_combs$seed[i]
  )
}

evaluated_grouped_sim_forest <- bind_rows(evaluated_grouped_sim_forest)
```

```{r}
evaluated_grouped_sim_forest <- evaluated_grouped_sim_forest %>%
  group_by(K_coarse) %>%
  summarize(
    FDR = mean(FDP),
    Power = mean(pow),
    n_monte_carlo = n(),
    pow_se = sd(pow) / sqrt(n_monte_carlo)
  ) %>%
  arrange(K_coarse, desc(Power)) %>%
  ungroup() 

saveRDS(evaluated_grouped_sim_forest, file= "huber_github/precomputed_results/evaluated_grouped_sim_forest.Rds")
```

## 1. BetaMix Example

Now we create the betamix sample data according to Section 5.2 in https://doi.org/10.1111/rssb.12411 with two-dimensional covariates
```{r create data}
mus_slope <- 1.5
prob_one_sided <- 0.25

Xs <- lapply(1:r, function(i) {
  Xs_i_i <- matrix(runif(m * 2, 0, 1), ncol = 2)
  colnames(Xs_i_i) <- c("X1", "X2")
  Xs_i_i
})

Hs <- lapply(Xs, function(Xs_i) {
  pi1s <- ifelse(Xs_i[, 1]^2 + Xs_i[, 2]^2 <= 1, 0.02, 0.4)
  Hs_i <- stats::rbinom(m, size = 1, prob = pi1s)
  Hs_i
})

Ps <- mapply(function(Xs_i, Hs_i) {
  mus <- pmax(1.3, sqrt(Xs_i) %*% c(1, 1) * mus_slope)
  mu_alphas <- 1 / mus
  Ps_i <- stats::runif(m) * (1 - Hs_i) + stats::rbeta(m, mu_alphas, 1) * Hs_i
  Ps_i
}, Xs, Hs)
```


To run the original IHW (quantile slicing) on two-dimensional covariates, we need to manually bin the covariates in 2d squares
```{r manually bin Xs_i}
bins1d <- seq(from = 0, to = 1, length.out = 6)
Xs_binned <- foreach(Xs_i = Xs) %dopar% {
  Xs_binned_i <- data.frame(
    X1 = cut(Xs_i[, 1], bins1d),
    X2 = cut(Xs_i[, 2], bins1d)
  )
  Xs_binned_i <- apply(Xs_binned_i, 1, function(row) {
    factor(paste(row[[1]], row[[2]], sep = "*"))
  })
  Xs_binned_i
}
```


We run the normal IHW with the binned covariates. The option `strat = "quantile"` makes it equivalent to the original IHW.

```{r run_IHW, message=T}
ihw_betamix_slic <- foreach(Xs_binned_i = Xs_binned, Ps_i = Ps) %dopar% {
  ihw(Ps_i, Xs_binned_i, alpha = alpha, folds = folds, strat = "quantile", lambda = lambda)
}
fdp_eval(ihw_betamix_slic, Hs)
##      rjs        pow        FDR
## 1 103.39 0.09449784 0.07155839
```

Now we run IHW with forest. 
```{r run_IHW_forest, message=FALSE}
ihw_betamix_forest <- foreach(Xs_i = Xs, Ps_i = Ps) %dopar% {
  ihw_forest <- ihw(Ps_i, Xs_i, alpha = alpha, folds = folds, strat = "BocaLeek", ntrees = ntrees, tau = tau, lambda = lambda)
}
fdp_eval(ihw_betamix_forest, Hs)
##      rjs       pow        FDR
## 1 151.26 0.1353382 0.08937585
```
We see, that the new method does indeed increase power while retaining FDR.

```{r, eval = T}
ihw_betamix_RFCDE <- foreach(Xs_i = Xs, Ps_i = Ps) %dopar% {
  ihw_forest <- ihw(Ps_i, Xs_i, alpha = alpha, folds = folds, strat = "RFCDE", ntrees = ntrees, tau = tau, lambda = lambda)
}
fdp_eval(ihw_betamix_RFCDE, Hs)
```



## 2. BetaMix with noise     
Lets add some uninformative noise. If this still works, this would be extremely convenient for the end user. Furthermore, so many dimensions definitely necessitates the use of regression trees. Due to the exponential increase of the number of bins with the dimension, quantile slicing would be computationally infeasible. The ability to incorporate high-dimensional covariates is the most convincing advantage of the random forest approach. 
```{r, message=FALSE, warning=FALSE}
ihw_betamix_noise_BocaLeek <- foreach(Xs_i = Xs, Ps_i = Ps) %dopar% {
  noise <- matrix(runif(m * 5), nrow = m)
  Xs_i <- cbind(Xs_i, noise)
  ihw_forest <- ihw(Ps_i, Xs_i, alpha = alpha, folds = folds, strat = "BocaLeek", ntrees = ntrees, tau = tau, lambda = lambda)
}
fdp_eval(ihw_betamix_noise_BocaLeek, Hs)
##      rjs       pow        FDR
## 1 471.17 0.4225245 0.08725322
```
```{r, message=FALSE, warning=FALSE}
ihw_betamix_noise_RFCDE <- foreach(Xs_i = Xs, Ps_i = Ps) %dopar% {
  noise <- matrix(runif(m * 5), nrow = m)
  Xs_i <- cbind(Xs_i, noise)
  ihw_forest <- ihw(Ps_i, Xs_i, alpha = alpha, folds = folds, strat = "RFCDE", ntrees = ntrees, tau = tau, lambda = lambda)
}
fdp_eval(ihw_betamix_noise_RFCDE, Hs)
##      rjs       pow        FDR
## 1 471.17 0.4225245 0.08725322
```

## 3. But does it work better in univariate case?
Lets return to a simple, univariate example. The official referencemanual (http://bioconductor.org/packages/release/bioc/manuals/IHW/man/IHW.pdf) works with following data.
```{r generatedata_univ, message=FALSE}
Xs <- lapply(1:r, function(i) {
  runif(m, min = 0, max = 2.5) # covariate
})
Hs <- lapply(1:r, function(i) {
  rbinom(m, 1, 0.1) # hypothesis true or false
})
Ps <- lapply(1:r, function(i) {
  Xs_i <- Xs[[i]]
  Hs_i <- Hs[[i]]
  Z_i <- rnorm(m, Hs_i * Xs_i) # Z-score
  Ps_i <- 1 - pnorm(Z_i) # pvalue
})
```

Lets run IHW forest and the quantile slicing on this: 
```{r run_IHW_univ, message=FALSE}
ihw_univ_slic <- foreach(Xs_i = Xs, Ps_i = Ps) %dopar% {
  ihw(Ps_i, Xs_i, alpha = alpha, folds = folds, strat = "quantile", lambda = lambda)
}
fdp_eval(ihw_univ_slic, Hs)
##     rjs        pow        FDR
## 1 89.41 0.08159328 0.08633605
```

And now we run IHW forest.
```{r}
ihw_univ_BocaLeek <- foreach(Xs_i = Xs, Ps_i = Ps) %dopar% {
  ihw(Ps_i, Xs_i, alpha = alpha, folds = folds, strat = "BocaLeek", ntrees = ntrees, tau = tau, lambda = lambda)
}
fdp_eval(ihw_univ_BocaLeek, Hs)
##     rjs        pow        FDR
## 1 64.59 0.05847762 0.09265819
```

So it turns out, that using the Boca Leek Tree actually did harm in this case. 
```{r}
ihw_univ_RFCDE <- foreach(Xs_i = Xs, Ps_i = Ps) %dopar% {
  ihw(Ps_i, Xs_i, alpha = alpha, folds = folds, strat = "RFCDE", ntrees = ntrees, tau = tau, lambda = lambda)
}
fdp_eval(ihw_univ_RFCDE, Hs)
##     rjs        pow        FDR
## 1 64.59 0.05847762 0.09265819
```

## 4. Airway data seit

Let's try some real biological data instead of simulation. We are not able check the FDR, but we are confident it is controlled. We benchmark on the airway data set, also used in the official vigniette (http://bioconductor.org/packages/release/bioc/vignettes/IHW/inst/doc/introduction_to_ihw.html). You can download the necessary packages `BiocManager::install("airway")` and `BiocManager::install("DESeq2")`.

```{r, load_airway, message = F}
library("DESeq2")
data("airway", package = "airway")
dds <- DESeq2::DESeqDataSet(se = airway, design = ~ cell + dex) %>% DESeq()
deRes <- as.data.frame(results(dds))
```

setting some parameters
```{r, message = F}
m <- nrow(deRes)
folds <- sample(1:nfolds, m, replace = TRUE)
```

We first run the original IHW.
```{r}
ihw_airway_slic <- ihw(pvalue ~ baseMean, data = deRes, alpha = alpha, folds = folds, lambda = lambda, strat = "quantile")
sum(IHW::rejected_hypotheses(ihw_airway_slic), na.rm = T) / m # pow
## [1] 0.07634707
```

And then IHW forest.
```{r, message = F}
ihw_airway_forest <- ihw(pvalue ~ baseMean, data = deRes, alpha = alpha, folds = folds, strat = "BocaLeek", ntrees = ntrees, tau = tau, lambda = lambda)
sum(IHW::rejected_hypotheses(ihw_airway_forest), na.rm = T) / m # pow
## [1] 0.07561387
```

```{r, message = F}
ihw_airway_RFCDE <- ihw(pvalue ~ baseMean, data = deRes, alpha = alpha, folds = folds, strat = "RFCDE", ntrees = ntrees, tau = tau, lambda = lambda)
sum(IHW::rejected_hypotheses(ihw_airway_RFCDE), na.rm = T) / m # pow
## [1] 0.07561387
```
Again, the we are actually worse off with the new method...

## Conclusion/Outlook
At its current stage, IHW forest is not performing as I had hoped. However, there is still room for improvement for random forest: Firstly, a smarter choice of tau might do the trick. Secondly, the random forest is currently only based on Boca Leek tree (https://peerj.com/articles/6035/). I have not managed to incorporate rfcde trees (https://arxiv.org/abs/1804.05753) yet. From a mathematical point of view, rfcde trees would be better than Boca Leek trees.

Further outlook: I want to restore the auto setting functionality of lambda and fold. Unfortunately, this is tricky, because major changes to the original code/order functions are executed are required. This is not a good problem for a code review session. Furthermore, the code in https://raw.github.com/FridljDa/IHW/main/bioconductor/R/ihw_convex_20211214.R is currently pretty hacky and not good enough for BioConductor.
