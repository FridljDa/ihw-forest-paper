---
title: "bocaleek_tree20211207"
output: html_document
---

```{r setup, include=FALSE}
library(ggplot2)
knitr::opts_chunk$set(echo = TRUE)
set.seed(123)
# Rcpp::sourceCpp("/g/huber/users/fridljand/R/IHW/bioconductor/C++/grenador.cpp")
# Rcpp::sourceCpp("/Volumes/fridljand/R/IHW/bioconductor/C++/grenador.cpp")
```

## R Markdown


```{r load_functions, echo = F, include=FALSE}
#script.dir <- "/Volumes/fridljand/R/IHW/bioconductor/R"
 script.dir <- "/g/huber/users/fridljand/R/IHW/bioconductor/R"
scripts <- list.files(script.dir)
lapply(scripts, function(script) {
  source(file.path(script.dir, script))
})
```

```{r create_fdp_eval, include=FALSE }
#' Evaluate multiple testing procedure
#
#' @param Hs Vector with indicators of alternatives (1) and true nulls (0)
#' @param rjs Vector with indicator of rejected hypotheses
#' @return Data frame with columns `rjs` (total rejections), `pow` (Power), `FDP` (False discovery proportion)
#' @export
fdp_eval <- function(Hs, rjs) {
  rjs_total <- sum(rjs)
  pow <- sum(rjs * Hs) / max(1, sum(Hs))
  FDP <- sum(rjs * (1 - Hs)) / max(1, rjs_total)
  FWER <- sum((1 - Hs) * rjs) > 0
  data.frame(rjs = rjs_total, pow = pow, FDP = FDP, FWER = FWER)
}
```
Lets first set some parameters
```{r set parameters}
m <- 10000
nfoldsI <- 3

folds <- sample(1:nfoldsI, m, replace = TRUE)
adjustment_type <- "BH"
```

Now we create the betamix sample data according to Section 5.2 with two-dimensional covariates
```{r create data}
mus_slope <- 1.5
prob_one_sided <- 0.25

Xs <- matrix(runif(m * 2, 0, 1), ncol = 2)
colnames(Xs) <- c("X1", "X2")

pi1s <- ifelse(Xs[, 1]^2 + Xs[, 2]^2 <= 1, 0.02, 0.4)
mus <- pmax(1.3, sqrt(Xs) %*% c(1, 1) * mus_slope)
mu_alphas <- 1 / mus

Hs <- stats::rbinom(m, size = 1, prob = pi1s)
Ps <- stats::runif(m) * (1 - Hs) + stats::rbeta(m, mu_alphas, 1) * Hs
```


To run regular IHW, we need to manually bin the covariates in 2d squares
```{r manually bin Xs}
bins1d <- seq(from = 0, to = 1, length.out = 6)

Xs_binned <- data.frame(
  X1 = cut(Xs[, 1], bins1d),
  X2 = cut(Xs[, 2], bins1d)
)
Xs_binned <- apply(Xs_binned, 1, function(row) {
  factor(paste(row[[1]], row[[2]], sep = "*"))
})
```

We run the normal IHW with the binned covariates
```{r run_IHW, message=FALSE}
ihw_no_forest <- ihw(Ps, Xs_binned, alpha = .1, folds = folds, use_forest = FALSE, adjustment_type = "BH", lp_solver = "lpsymphony", lambda = Inf)
```

Now we run the IHW Forest with 100 trees. For the Boca Leek tree we need to provide the censoring parameter tau. The exact value of tau should not be too important. We will revisit this issue in a later stage of the project. 

```{r run_IHW_forest, message=FALSE}
tau <- 0.7
ihw_forest <- ihw(Ps, Xs, alpha = .1, folds = folds, use_forest = TRUE, ntrees = 100, tau = tau, lp_solver = "lpsymphony", lambda = Inf)
```

## Evaluating and comparing
Lets have a look at power and FDP. Note that as Nikos, we are only using one MonteCarlo replicate. So the FDP should be interpreted with caution. However, I am confident that I am not violating any assumptions of the theorems (took special care of that), so FDR control should be guaranteed from a theoretical point of view. We see that for this example, that the forest structure increases power considerably.
```{r fdp_eval}
fdp_eval_no_forest <- fdp_eval(Hs, IHW::rejected_hypotheses(ihw_no_forest))
fdp_eval_forest <- fdp_eval(Hs, IHW::rejected_hypotheses(ihw_forest))
rbind(
  manually_cut = fdp_eval_no_forest,
  use_forest = fdp_eval_forest
)
```

For completeness, let's plot the weights in 2d as in Nikos' draft of proof pdf
```{r plot_weights no forest}
data <- data.frame(Xs, weight = ihw_no_forest@df[["weight"]])
ggplot(data = data, aes(x = X1, y = X2, color = weight)) +
  geom_point()
```

```{r plot_weights forest}
data <- data.frame(Xs, weight = ihw_forest@df[["weight"]])
ggplot(data = data, aes(x = X1, y = X2, color = weight)) +
  geom_point()
```
## Noise extra dimensions      
Lets add some uninformative noise. If this still works, this would be extremely convenient for the end -user and disencourage active cheating. Furthermore, so many dimensions definitly necessitates the use regression trees. 
```{r, message=FALSE, warning=FALSE}
noise_dim <- 5
noise <- runif(m*noise_dim)
noise <- matrix(noise, nrow = m, ncol = noise_dim)
Xs <- cbind(Xs, noise)       
ihw_forest_noisy <- ihw(Ps, Xs, alpha = .1, folds = folds, use_forest = TRUE, ntrees = 100, tau = tau, lp_solver = "lpsymphony", lambda = Inf) 
fdp_eval(Hs, IHW::rejected_hypotheses(ihw_forest_noisy))         
                                                           
```

## But does it work better in univariate case?
Lets return to a simple, univariate example. The official referencemanual work with following data
```{r generatedata_univ, echo=FALSE}
Xs <- runif(m, min = 0, max = 2.5) # covariate
Hs <- rbinom(m, 1, 0.1) # hypothesis true or false
Z <- rnorm(m, Hs * Xs) # Z-score
# .Random.seed <- save.seed
Ps <- 1 - pnorm(Z) # pvalue
```

Lets run IHW forest and the quantile slicing on this: 
```{r run_IHW_univ, message=FALSE}
ihw_quantile_slicing <- ihw(Ps, Xs, alpha = .1, folds = folds, use_forest = FALSE, adjustment_type = "BH", lp_solver = "lpsymphony", lambda = Inf)
ihw_forest <- ihw(Ps, Xs, alpha = .1, folds = folds, use_forest = TRUE, ntrees = 100, tau = tau, lp_solver = "lpsymphony", lambda = Inf)
rbind(
  quantile_slicing = fdp_eval(Hs, IHW::rejected_hypotheses(ihw_quantile_slicing)),
  use_forest = fdp_eval(Hs, IHW::rejected_hypotheses(ihw_forest))
)
```

## Conclusion
We need to do better benchmarking, with different models and more repkicates.