---
title: "Boca Leek IHW Benchmark"
output: html_document
---

```{r setup, include=FALSE}
# clear memory
rm(list = ls(all = TRUE))

library(magrittr)
knitr::opts_chunk$set(echo = TRUE)
set.seed(123)

library(doParallel)
n.cores <- parallel::detectCores()
doParallel::registerDoParallel(cores = n.cores - 1)
library(doRNG)
```

## Preperation

This will be the function to evaluate the IHW results. We want to control the False Discovery Rate (FDR) at a prespecified level, typically 0.1. We want to maximize power, e.g. number of discoveries.
```{r create_fdp_eval}
fdp_eval <- function(IHW_results, Hs) {
  # evaluating all Monte Carlo replicates
  fdp_compare_r <- mapply(function(IHW_results_i, Hs_i) {
    rjs <- IHW::rejected_hypotheses(IHW_results_i)
    rjs_total <- sum(rjs)
    pow <- sum(rjs * Hs_i) / max(1, sum(Hs_i))
    FDP <- sum(rjs * (1 - Hs_i)) / max(1, rjs_total)
    data.frame(rjs = rjs_total, pow = pow, FDP = FDP)
  }, IHW_results, Hs)

  fdp_compare_r <- as.data.frame(t(fdp_compare_r))

  # taking the average
  fdp_compare_r <- fdp_compare_r %>%
    dplyr::summarise(
      rjs = mean(as.numeric(rjs)),
      pow = mean(as.numeric(pow)), # this should be maximized
      FDR = mean(as.numeric(FDP)) # this should be controlled at a pre-specified level alpha
    )
  return(fdp_compare_r)
}
```

Loading my current status of the code (work in progress...). Would there be a more elegant way, to test my code without building the package every time? I also want to set breakpoints in the code for debugging.
```{r load_functions, echo = F, , message = F, eval = F}
source("https://raw.github.com/FridljDa/IHW/main/bioconductor/R/helpers.R")
source("https://raw.github.com/FridljDa/IHW/main/bioconductor/R/ihw_class.R")
source("https://raw.github.com/FridljDa/IHW/main/bioconductor/R/ihw_convex_20211214.R")
source("https://raw.github.com/FridljDa/IHW/main/bioconductor/R/weights.R")
```

```{r load_functions, echo = F, message = F, eval = T}
source("/Volumes/fridljand/R/IHW/bioconductor/R/helpers.R")
source("/Volumes/fridljand/R/IHW/bioconductor/R/ihw_class.R")
source("/Volumes/fridljand/R/IHW/bioconductor/R/ihw_convex_20211214.R")
source("/Volumes/fridljand/R/IHW/bioconductor/R/weights.R")
```

Setting some parameters used throughout. 
```{r set_parameters}
m <- 10000
r <- 1 # number of monte carlo replicates, increases run time immensely!
alpha <- .1
```

The following parameters are auto-set in the BioConductor implementation. My code is not capable of this yet. 
```{r set_parameters2}
nfolds <- 3
folds <- sample(1:nfolds, m, replace = TRUE)
lambda <- Inf
```

For the random forest approach, a censoring parameter tau is introduced. I will revisit auto setting later. ntrees controlls the number of trees in each random forest.
```{r set_parameters3}
tau <- 0.7 # censoring parameter for BocaLeek estimator
ntrees <- 100 # number of trees per forest
```

## 1. BetaMix Example

Now we create the betamix sample data according to Section 5.2 in https://doi.org/10.1111/rssb.12411 with two-dimensional covariates
```{r create data}
mus_slope <- 1.5
prob_one_sided <- 0.25

Xs <- lapply(1:r, function(i) {
  Xs_i_i <- matrix(runif(m * 2, 0, 1), ncol = 2)
  colnames(Xs_i_i) <- c("X1", "X2")
  Xs_i_i
})

Hs <- lapply(Xs, function(Xs_i) {
  pi1s <- ifelse(Xs_i[, 1]^2 + Xs_i[, 2]^2 <= 1, 0.02, 0.4)
  Hs_i <- stats::rbinom(m, size = 1, prob = pi1s)
  Hs_i
})

Ps <- mapply(function(Xs_i, Hs_i) {
  mus <- pmax(1.3, sqrt(Xs_i) %*% c(1, 1) * mus_slope)
  mu_alphas <- 1 / mus
  Ps_i <- stats::runif(m) * (1 - Hs_i) + stats::rbeta(m, mu_alphas, 1) * Hs_i
  Ps_i
}, Xs, Hs)
```


To run the original IHW (quantile slicing), we need to manually bin the covariates in 2d squares %TODO
```{r manually bin Xs_i}
bins1d <- seq(from = 0, to = 1, length.out = 6)
Xs_binned <- lapply(Xs, function(Xs_i) {
  Xs_binned_i <- data.frame(
    X1 = cut(Xs_i[, 1], bins1d),
    X2 = cut(Xs_i[, 2], bins1d)
  )
  Xs_binned_i <- apply(Xs_binned_i, 1, function(row) {
    factor(paste(row[[1]], row[[2]], sep = "*"))
  })
  Xs_binned_i
})
```

IHW is currently working with quantile slicing. 
We run the normal IHW with the binned covariates. use_forest = FALSE makes it equivalent to the normal thing.

```{r run_IHW, message=FALSE}
ihw_betamix_slic <- foreach(Xs_binned_i = Xs_binned, Ps_i = Ps) %dopar% {
  ihw(Ps_i, Xs_binned_i, alpha = alpha, folds = folds, use_forest = FALSE, lambda = lambda)
}
fdp_eval(ihw_betamix_slic, Hs)
```
This is the new method
```{r run_IHW_forest, message=FALSE}
ihw_betamix_forest <- foreach(Xs_i = Xs, Ps_i = Ps) %dopar% {
  ihw_forest <- ihw(Ps_i, Xs_i, alpha = alpha, folds = folds, use_forest = TRUE, ntrees = ntrees, tau = tau, lambda = lambda)
}
fdp_eval(ihw_betamix_forest, Hs)
```
We see, that the new method does indeed increase power while retaining FDR.

## 2. BetaMix with noise     
Lets add some uninformative noise. If this still works, this would be extremely convenient for the end user. Furthermore, so many dimensions definitely necessitates the use of regression trees. Due to the exponential increase of the number of bins with the dimension, quantile slicing would be computationally infeasible. The ability to incorporate high-dimensional covariates is the most convincing advantage of the random forest approach. 
```{r, message=FALSE, warning=FALSE}
ihw_betamix_noise_slic <- foreach(Xs_i = Xs, Ps_i = Ps) %dopar% {
  noise <- matrix(runif(m * 5), nrow = m)
  Xs_i <- cbind(Xs_i, noise)
  ihw_forest <- ihw(Ps_i, Xs_i, alpha = alpha, folds = folds, use_forest = TRUE, ntrees = ntrees, tau = tau, lambda = lambda)
}
fdp_eval(ihw_betamix_noise_slic, Hs)
```

## 3. But does it work better in univariate case?
Lets return to a simple, univariate example. The official referencemanual (http://bioconductor.org/packages/release/bioc/manuals/IHW/man/IHW.pdf) work with following data.
```{r generatedata_univ, message=FALSE}
Xs <- lapply(1:r, function(i) {
  runif(m, min = 0, max = 2.5) # covariate
})
Hs <- lapply(1:r, function(i) {
  rbinom(m, 1, 0.1) # hypothesis true or false
})
Ps <- lapply(1:r, function(i) {
  Xs_i <- Xs[[i]]
  Hs_i <- Hs[[i]]
  Z_i <- rnorm(m, Hs_i * Xs_i) # Z-score
  Ps_i <- 1 - pnorm(Z_i) # pvalue
})
```

Lets run IHW forest and the quantile slicing on this: 
```{r run_IHW_univ, message=FALSE}
ihw_univ_slic <- foreach(Xs_i = Xs, Ps_i = Ps) %dopar% {
  ihw(Ps_i, Xs_i, alpha = alpha, folds = folds, use_forest = FALSE, lambda = lambda)
}
fdp_eval(ihw_univ_slic, Hs)
```

```{r}
ihw_univ_forest <- foreach(Xs_i = Xs, Ps_i = Ps) %dopar% {
  ihw(Ps_i, Xs_i, alpha = alpha, folds = folds, use_forest = TRUE, ntrees = ntrees, tau = tau, lambda = lambda)
}
fdp_eval(ihw_univ_forest, Hs)
```
TODO rename results
So it turns out, that using the Boca Leek Tree actually did harm in this case. 
## 4. real data 
http://bioconductor.org/packages/release/bioc/vignettes/IHW/inst/doc/introduction_to_ihw.html
```{r, load_airway, message = F, echo = F}
library("DESeq2")
library("dplyr")
data("airway", package = "airway")
dds <- DESeqDataSet(se = airway, design = ~ cell + dex) %>% DESeq
deRes <- as.data.frame(results(dds))
```

```{r}
m <- nrow(deRes)
folds <- sample(1:nfolds, m, replace = TRUE)
```

```{r}
ihw_airway_slic <- ihw(pvalue ~ baseMean,  data = deRes, alpha = alpha, folds = folds,  lambda = lambda, use_forest = FALSE)
sum(IHW::rejected_hypotheses(ihw_airway_slic), na.rm = T)
```

could easily consider other covariates than baseMean
```{r}
ihw_airway_forest <- ihw(pvalue ~ baseMean,  data = deRes, alpha = alpha, folds = folds, use_forest = TRUE, ntrees = ntrees, tau = tau, lambda = lambda)
sum(IHW::rejected_hypotheses(ihw_airway_forest), na.rm = T)
```

## Conclusion/Outlook
The random forest approach can pick up heterogeneity in the data is more appropriate for more complex data. For data with a simple underlying generating mechanism, this advantage is outweighed by quantile slicing having a similar number of observations per bin (desirable in general). I had hoped that random forest would consistently outperform quantile slicing. However, in real applications with complex data random forest will likely beat quantile slicing. Also, there is still room for improvement for random forest: Firstly, a smarter choice of tau might do the trick. Secondly, the random forest is currently only based on Boca Leek tree (https://peerj.com/articles/6035/). I have not tried incorporating rfcde trees (https://arxiv.org/abs/1804.05753) yet.   

Further outlook: I want to restore the auto setting functionality of lambda and fold. Unfortunantly, this is tricky, because major changes to the original code/order functions are executed are required. This is not a good problem for a code review session. Furthermore, the code in https://raw.github.com/FridljDa/IHW/main/bioconductor/R/ihw_convex_20211214.R is currently pretty hacky and not good enough for BioConductor.

ihw.formula for multiple covariates
