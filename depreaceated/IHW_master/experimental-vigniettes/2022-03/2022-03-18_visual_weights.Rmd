---
title: "IHW simple Benchmark"
output: html_document
---


Loading packages.
```{r setup, message = F}
library(magrittr)
library(dplyr)
library(ggplot2)
knitr::opts_chunk$set(echo = TRUE)
set.seed(1234)
theme_set(theme_bw())
```

Generate simulation from https://support.bioconductor.org/p/90005/#9137847. 
```{r}
# test data
m_test <- 100
m <- 1e4
nfolds <- 3
#folds <- sample(1:nfolds, m, replace = TRUE)
```

```{r}
prop_alt <- function(cov1, cov2){
  1 / (1 + exp(-cov1))
  #1 / (1 + exp(-1 * (3 * cov1 - 5)))
  #abs(sin(pi*cov1))
}
```

```{r}
data_train <- data.frame(
  cov1 = runif(m, -1, 1),
  cov2 = runif(m, -1, 1)
)

data_train <- data_train %>%
  mutate(
    prop_alt = prop_alt(cov1, cov2),
    Hs = rbinom(n(), size = 1, prop_alt),
    pvalue = ifelse(Hs,
      rbeta(n(), 0.25, 1),
      runif(n())
    )
  )

data_test <- expand.grid(
  cov1 = seq(-1, 1, length.out = m_test),
  cov2 = seq(-1, 1, length.out = m_test)
)

data_test <- data_test %>% mutate(
  prop_alt = prop_alt(cov1, cov2),
  Hs = rbinom(n(), size = 1, prop_alt),
  pvalue = ifelse(Hs,
    rbeta(n(), 0.25, 1),
    runif(n())
  )
)

data_train_test <- rbind(data_train, data_test)
folds <- c(rep(1, nrow(data_train)), rep(2, nrow(data_test)))
#names(covariate_noise) <- c("cov1", "cov2")
# colnames(data_test) <- colnames(covariate_noise)
```

```{r}
data_true <- expand.grid(
  cov1 = seq(-1, 1, length.out = m_test),
  cov2 = seq(-1, 1, length.out = m_test)
)

data_true <- data_true %>%
  mutate( prop_alt = prop_alt(cov1, cov2),
  true_alt_expectation = 0.25 / (0.25 + 1),
  cond_exp = 0.5 + prop_alt * (0.5 - true_alt_expectation),
  )
```

Loading my working version of IHW ucosg random forest. 
```{r load_functions, eval = T, message=F, results='hide'}
devtools::load_all()
# devtools::install_github("FridljDa/RFCDE")
# library("IHW")
# devtools::load_all("../../../RFCDE")
```


Set parameters for IHW Forest
```{r set_parameters3}
#tau <- 0.5 # censoring parameter for BocaLeek estimator
# nbasis <- 10L
# nbins <- 10L
lambda <- Inf

ntrees <- 5L # number of trees per forest
ntaus <- 10
taus <- NULL

maxdepth <- 6 #3 worked well!
min.node.size <- 1000
nsplit <- 5
nbins <- 4L
```




```{r, eval=F}
fdp_eval <- function(Hs, rjs){
  rjs_total <- sum(rjs)
  correct_rej <- sum(rjs*Hs)
  pow <- sum(rjs*Hs)/max(1,sum(Hs))
  FDP <- sum(rjs*(1-Hs))/max(1,rjs_total)
  data.frame(rjs=rjs_total, pow=pow, correct_rej = correct_rej, FDP=FDP)
}
```

```{r, eval = F}
evaluated_bh <- fdp_eval(Hs = data_train$Hs, rjs = rjs_bh)
evaluated_quantile <- fdp_eval(Hs = data_train$Hs, rjs = rjs_quantile)
evaluated_bocaleek <- fdp_eval(Hs = data_train$Hs, rjs = rjs_bocaleek)
evaluated_julia <- fdp_eval(Hs = data_train$Hs, rjs = rjs_julia)
rbind(evaluated_bh,
      evaluated_quantile,
      evaluated_bocaleek)
evaluated_quantile$pow< evaluated_bocaleek$pow
```

```{r}
groups_cut <- groups_by_cut(select(data_test, starts_with("cov")), nbins)

data_cut <- cbind(data_test, groups_cut)

data_cut <- data_cut %>%
  group_by(group) %>%
  mutate(ecdf = 1 - mean(pvalue)) %>%
  ungroup() 

data_cut <- data_cut %>%
  group_by(cov1, cov2) %>%
  summarize(ecdf = mean(ecdf)) %>%
  ungroup() 
```

```{r}
groups_bocaleek <- group_by_forest_BocaLeek(data_train_test$pvalue, select(data_train_test, starts_with("cov")), folds, nbins=nbins, ntrees = ntrees, taus = taus, ntaus = ntaus, maxdepth = maxdepth, min.node.size = min.node.size, nsplit = nsplit) 
groups_bocaleek_test <-  groups_bocaleek[folds==2,]

data_bocaleek <- cbind(data_test, groups_bocaleek_test)

data_bocaleek <- data_bocaleek %>%
  tidyr::pivot_longer(
    starts_with("group"),
    names_to = "tree",
    values_to = "tree_group"
  )

data_bocaleek <- data_bocaleek %>%
  group_by(tree, tree_group) %>%
  mutate(ecdf = 1 - mean(pvalue)) %>%
  ungroup() 
```
cherry picking
```{r, eval = F}
plots_bocaleek_simpl <- lapply(names(groups_bocaleek), function(group_i){
  data_bocaleek_simpl_i <- data_bocaleek %>%
  filter(tree == group_i) %>% #group1 looks best
  group_by(cov1, cov2) %>%
  summarize(ecdf = mean(ecdf)) %>%
  ungroup() 
  
  data_bocaleek_simpl_i %>%
  ggplot(aes(cov1, cov2, color = ecdf)) +
  geom_point()
})

ggsave("~/R/IHW-1/figures/arrange2x2.pdf", gridExtra::marrangeGrob(grobs = plots_bocaleek_simpl, nrow=2, ncol=2),
device = "pdf")

```

```{r}
data_bocaleek_simpl <- data_bocaleek %>%
  filter(tree == "group12") %>% #group1 looks best
  group_by(cov1, cov2) %>%
  summarize(ecdf = mean(ecdf)) %>%
  ungroup() 

data_bocaleek <- data_bocaleek %>%
  group_by(cov1, cov2) %>%
  summarize(ecdf = mean(ecdf)) %>%
  ungroup() 
```

```{r}
limits = c(min(c(data_true$cond_exp, data_cut$ecdf, data_bocaleek_simpl$ecdf, data_bocaleek$ecdf)),max(c(data_true$cond_exp, data_cut$ecdf, data_bocaleek_simpl$ecdf, data_bocaleek$ecdf)))
```

```{r}
myPalette <- colorRampPalette(rev(RColorBrewer::brewer.pal(11, "Spectral")))
#range(data_true$cond_exp)
g1 <- data_true %>%
  ggplot(aes(cov1, cov2, color = cond_exp)) +
  geom_point() +
  scale_colour_gradientn(colours = myPalette(100), limits=limits)+
  labs(color = "Conditional Expectation") +
  ggtitle("True model")
```

```{r}
g2 <- data_cut %>%
  ggplot(aes(cov1, cov2, color = ecdf)) +
  geom_point()+
  scale_colour_gradientn(colours = myPalette(100), limits=limits) +
  ggtitle("Quantile slicing")
```

```{r}
g3 <- data_bocaleek_simpl %>%
  ggplot(aes(cov1, cov2, color = ecdf)) +
  geom_point()+
  scale_colour_gradientn(colours = myPalette(100), limits=limits) +
  ggtitle("Boca Leek single Tree")
```
much more nuanced.
```{r, eval = T}
g4 <- data_bocaleek %>%
  ggplot(aes(cov1, cov2, color = ecdf)) +
  geom_point()+
  scale_colour_gradientn(colours = myPalette(100), limits=limits) +
  ggtitle("Boca Leek Forest (T=100)")
```

```{r}
g_combined <- ggpubr::ggarrange(g1, g2, g3, g4, ncol = 2, nrow = 2, common.legend = TRUE, legend="bottom") 
ggplot2::ggsave("~/R/IHW-1/figures/visual_weights.png", g_combined,
                width = 10, height = 7.5)
g_combined
```

main take aways:
it prioritizes more informative covariates
extreme case: it can ignore irrelevant covariates
random forest => smoother, more steps, without violating the optimization constraint
can capture variation better
sensitive to small regions => we want to assign high priority those
quantile slicing does not extend to high dimensional covariates at all, because of exponential increase
quantile slicing only depends on covariates, not p-values