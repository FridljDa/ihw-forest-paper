---
title: "hQTL analysis with IHW-Benjamini-Yekutieli"
author: "Danie Fridljand"
date: "`r doc_date()`"
output: BiocStyle::html_document
header-includes:
   - \usepackage{bbm}
vignette: >
  %\VignetteIndexEntry{"IHW-Forest-paper: hQTL analysis with IHW-Benjamini-Yekutieli"}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---


```{r warning=FALSE, message=FALSE}
library(IHW)
library(fdrtool)
library(ggplot2)
library(cowplot)
theme_set(theme_cowplot())
library(tidyr)
library(scales)
library(latex2exp)
library(dplyr)
require(biomaRt)
set.seed(1)
```

```{r setup, include=FALSE, cache = FALSE}
knitr::opts_knit$set(root_dir = "/g/huber/users/fridljand/R/ihw-forest-paper/")
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
```

```{r hard_coding_path}
# file_loc <- system.file("extdata", "real_data", "hqtl_chrom1_chrom2", package = "IHWpaper")
# file_loc <- "/g/huber/users/fridljand/R/ihw-forest-paper/data/hqtl_chrom1_chrom2/"
root_dir <- "/g/huber/users/fridljand/R/ihw-forest-paper/"
# root_dir <- "/Users/default/Google Drive/currentDocumants/Studium/Master/3.Semester/Masterarbeit/Code/ihw-forest-paper/data/hqtl_chrom1_chrom2/"
# root_dir <- "/Volumes/huber/users/fridljand/R/ihw-forest-paper"
options(bitmapType = "cairo")
```

# Load SNPs and peaks
In this markdown, we apply several multiple testing procedures to the same hQTL analysis as in https://rss.onlinelibrary.wiley.com/doi/10.1111/rssb.12411?af=R, Section 6: APPLICATION EXAMPLE: BIOLOGICAL HIGH-THROUGHPUT DATA. The corresponding vigniette of the old analysis can be found [here](http://bioconductor.org/packages/release/data/experiment/vignettes/IHWpaper/inst/doc/hqtl_IHW_BY.html). In this analysis, the p-values were plotted against the genomic distance and the user had to manually figure out stratification breaks for IHW. Here we want to use the data-driven, automated stratification_methods `"quantile"` and `"forest"`. 


Recall that each hypothesis in an hQTL analysis corresponds to a peak of histone modification (which we call gene below) and a SNP. Hence let us the load files about each of the SNPs 

```{r loading_snp_peak}
snp_chr1 <- readRDS(file.path(root_dir, "data/hqtl_chrom1_chrom2/snppos_chr1.Rds")) %>% dplyr::select(snp, pos)
snp_chr2 <- readRDS(file.path(root_dir, "data/hqtl_chrom1_chrom2/snppos_chr2.Rds")) %>% dplyr::select(snp, pos)
head(snp_chr1)
```

and peaks:
```{r}
all_peaks <- readRDS(file.path(root_dir, "data/hqtl_chrom1_chrom2/peak_locations.Rds"))
peaks_chr1 <- dplyr::filter(all_peaks, chr == "chr1") %>% dplyr::select(id, start, end)
peaks_chr2 <- dplyr::filter(all_peaks, chr == "chr2") %>% dplyr::select(id, start, end)
rm(all_peaks)
head(peaks_chr1)
```

```{r, eval = F, include = F}
range_dist <- c()
pb = txtProgressBar(min = 0, max = nrow(peaks_chr2), initial = 0) 

for (i in 1:nrow(peaks_chr2)){
 # i <- 1
  setTxtProgressBar(pb,i)
  start_pos <- peaks_chr2$start[i]
  end_pos <- peaks_chr2$end[i]
  dist_vec <- pmin( abs(snp_chr2$pos - start_pos), abs(snp_chr2$pos - end_pos) )
  range_dist <- c(range_dist, dist_vec)
  range_dist <- range(range_dist)
}

formatC(range_dist, format = "e", digits = 2)
```

We have pre-calculated the p-values for these hypotheses beforehand, we are going to load now.

```{r loading_pvalues}
chr1_df <- readRDS(file.path(root_dir, "data/hqtl_chrom1_chrom2/chr1_subset.Rds")) %>% dplyr::select(SNP, gene, pvalue)
chr2_df <- readRDS(file.path(root_dir, "data/hqtl_chrom1_chrom2/chr2_subset.Rds")) %>% dplyr::select(SNP, gene, pvalue)
```
Note that only p-values <= 1e-4 are stored in these files to save data storage. For details, how the pvalues are calculated, see [code](https://github.com/nignatiadis/IHWpaper/blob/master/inst/real_data_examples/hqtl_example_analysis.R#L96). 
```{r}
pval_threshold <- 10^(-4)
```

Hence, the censored p-values follow the model 
\begin{eqnarray}
&P_i \mid H_i = 0 \sim U[0,10^(-4)]
\end{eqnarray}

However, all multiple testing used in this vigniette assume 
\begin{eqnarray}
&P_i \mid H_i = 0 \sim U[0,1]
\end{eqnarray}
We address this gap by artificially inflating the p-values:  
```{r}
chr1_df <- chr1_df %>% mutate(pvalue = pvalue / pval_threshold)
chr2_df <- chr2_df %>% mutate(pvalue = pvalue / pval_threshold)
```

# Load covariates
The IHW multiple testing procedure can incorporate additional side information to gain statistical power.

## genomic distance
We calculate the genomic distance between peaks and SNPs for all hypotheses. As [in the original analysis](http://bioconductor.org/packages/release/data/experiment/vignettes/IHWpaper/inst/doc/hqtl_IHW_BY.html), they are going to serve as main covariates for the multiple testing procedure.

```{r}
chr1_df <- left_join(chr1_df, snp_chr1, by=(c("SNP"="snp"))) %>%
       left_join(peaks_chr1, by=(c("gene"="id"))) %>%
       transmute(SNP, gene, pvalue, dist = pmin(abs(pos-start), abs(pos-end)))

chr2_df <- left_join(chr2_df, snp_chr2, by=(c("SNP"="snp"))) %>%
       left_join(peaks_chr2, by=(c("gene"="id"))) %>%
       transmute(SNP, gene, pvalue, dist = pmin( abs(pos-start), abs(pos-end)))
```

## Minor Allele Frequency
In [here](http://bioconductor.org/packages/release/data/experiment/vignettes/IHWpaper/inst/doc/hqtl_IHW_BY.html) only the genomic distance was used as covariate. Here, we also want to use minor allele frequency (MAF). We load the pre-downloaded MAF file. The data was pre-downloaded with `Biomart`.
```{r, eval = T}
chr1_maf <- readRDS(file = file.path(root_dir, "data/downloaded_covariates/chr1_maf.Rds"))
chr2_maf <- readRDS(file = file.path(root_dir, "data/downloaded_covariates/chr2_maf.Rds"))
```

We annotate the hypotheses with the MAF data.
```{r}
chr1_df <- chr1_df %>% left_join(chr1_maf, by = c("SNP" = "refsnp_id")) 
chr2_df <- chr2_df %>% left_join(chr2_maf, by = c("SNP" = "refsnp_id"))
```

Many MAFs are not available on `Biomart`. 
```{r}
chr1_maf_missing <- sum(is.na(chr1_df$minor_allele_freq))/nrow(chr1_maf)
chr2_maf_missing <- sum(is.na(chr2_df$minor_allele_freq))/nrow(chr2_maf)

paste0(round(100* chr1_maf_missing, 2), "%")
paste0(round(100* chr2_maf_missing, 2), "%")
```

For IHW, missing covariates are not allowed. So we conservatively replace all `NA`s with 0. 
```{r}
chr1_df <- chr1_df %>% mutate(minor_allele_freq = replace_na(minor_allele_freq, 0))
chr2_df <- chr2_df %>% mutate(minor_allele_freq = replace_na(minor_allele_freq, 0))
```

## H3K27Ac, H3K4me3, kH3k4me1, DNAse
Additionally, we source some covariates from the genome browser. For more information on each covariate, please lookup the corresponding track and table on `rtracklayer::trackNames` or on
http://genome.ucsc.edu/cgi-bin/hgTables?org=Human&db=hg19. 
```{r}
readRDS(file.path(root_dir, "data/downloaded_covariates/meta_track_table.Rds"))
```

We mapped the the information to the covariate by taking the closest genomic region.
```{r, eval=TRUE}
chr1_more_cov <- readRDS(file.path(root_dir, "data/downloaded_covariates/snp_chr1_cov_df.Rds"))
chr2_more_cov <- readRDS(file.path(root_dir, "data/downloaded_covariates/snp_chr2_cov_df.Rds"))

names_more_cov <- setdiff(names(chr1_more_cov), c("SNP", "gene"))
chr1_df <- chr1_df %>% left_join(chr1_more_cov, by = c("SNP", "gene")) 
chr2_df <- chr2_df %>% left_join(chr2_more_cov, by = c("SNP", "gene"))
```

## Checks

```{r}
any(is.na(chr1_df))
any(is.na(chr2_df))
```


```{r}
chr1_chr2_df <- rbind(chr1_df, chr2_df)
folds_vec <- as.factor(c(rep(1, nrow(chr1_df)), rep(2, nrow(chr2_df))))
rm(chr1_df, chr2_df)
rm(snp_chr1, peaks_chr1, snp_chr2, peaks_chr2)
rm(chr1_maf, chr2_maf)
rm(chr1_more_cov, chr2_more_cov)

chr1_chr2_df <- chr1_chr2_df %>% 
  dplyr::select(-one_of(c("SNP"))) 
```

# Apply IHW-BY and BY
## Run Multiple testing procedures
We want to apply the Benjamini-Yekutieli at alpha=0.1, thus we will apply Benjamini-Hochberg at the corrected level:

```{r}
m <- nrow(chr1_chr2_df)
alpha <- .01 / (log(m) + 1)
```

```{r, include=FALSE}
#we do not actually want to calculate all the time
run_write_ihw <- FALSE
```

```{r}
formulas_mt <- c("dist",
  "minor_allele_freq",
  "dist + minor_allele_freq",
  paste(c("dist","minor_allele_freq", names_more_cov), collapse = " + "),
  paste(c("dist","minor_allele_freq", names_more_cov[endsWith(names_more_cov, 'snp')]), collapse = " + "))

formulas_mt <- paste0("pvalue ~ ", formulas_mt)
formulas_mt <- sapply(formulas_mt, as.formula)
formulas_mt
```
Now let us run IHW with the `"quantile"` stratification method using different subsets of the available covariates:
```{r}
error_handler <- function(x) {
  if (inherits(x, "try-error")){
    x <- NA
  }
  x
}
```

```{r ihw_quantile_dist, include=TRUE, eval=run_write_ihw}
ihw_quantile <- lapply(formulas_mt, function(formulas_mt_i){
  error_handler(try(ihw(formulas_mt_i, data = chr1_chr2_df, alpha, folds = folds_vec)))
})
```

```{r, include=FALSE, eval=run_write_ihw}
saveRDS(ihw_quantile, file = file.path(root_dir, "precomputed_results/ihw_quantile.Rds"))
```

```{r, include=FALSE, eval=TRUE}
ihw_quantile <- readRDS(file = file.path(root_dir, "precomputed_results/ihw_quantile.Rds"))
```

Run IHW with the `"forest"` stratification method using different subsets of the available covariates:
```{r ihw_forest_dist, eval = run_write_ihw, warning= FALSE}
ihw_forest <- lapply(formulas_mt, function(formulas_mt_i){
  ihw_forest_i <- ihw(formulas_mt_i, data = chr1_chr2_df, alpha, folds = folds_vec,
                        stratification_method = "forest",
  n_censor_thres = 5, ntrees = 5, nodedepth = 6, nodesize = 5000)
})
```

```{r, include=FALSE, eval=run_write_ihw}
saveRDS(ihw_forest, file = file.path(root_dir, "precomputed_results/ihw_forest.Rds"))
```

```{r, include=FALSE, eval=TRUE}
ihw_forest <- readRDS(file = file.path(root_dir, "precomputed_results/ihw_forest.Rds"))
```

## Evaluate number of rejections
Rejections of BY:

```{r}
sum(p.adjust(na.exclude(chr1_chr2_df$pvalue), method = "BH") <= alpha)
```
In the [original analysis](http://bioconductor.org/packages/release/data/experiment/vignettes/IHWpaper/inst/doc/hqtl_IHW_BY.html), where we did not inflate the `pvalue` by the `p_value_threshold`, we had 9110 rejections with BY, so this is very similar.

Rejections of IHW-BY using different stratification methods:

```{r}
rejections_na <- function(ihw){
  if(is.na(ihw)){
    return(NA)
  }else{
    rejections(ihw)
  }
}
```

```{r}
result <- data.frame(
           quantile_rej = sapply(ihw_quantile, rejections_na),
           forest_rej = sapply(ihw_forest, rejections_na)
           )
result <- tibble::rownames_to_column(result, "formula")
result[,c(2,3,1)]
```

So we see that the number of discoveries has increased in most cases compared to BH. MAF turned out to be not informative, but decreased number of rejections for all stratification methods. However, while IHW-quantile was completely thrown of by an this extra dimension and reduced to classical BY with uniform weights, IHW-Forest was able to handle it.

```{r, eval = T, include=T}
# Plain latex output 
knitr::kable(result[,c(2,3,1)], "latex")
  #knitr::kbl(caption = "Example", # Adding caption  
  #      format = "latex") #%>% # Output format = latex 
   # knitr::kable_classic(html_font = "Cambria") # Font = Cambria 
```
# Session Info Details
```{r, echo=FALSE, eval=TRUE}
sessionInfo()
```
