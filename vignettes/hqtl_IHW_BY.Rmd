---
title: "hQTL analysis with IHW-Benjamini-Yekutieli"
author: "Danie Fridljand"
date: "`r doc_date()`"
output: BiocStyle::html_document
header-includes:
   - \usepackage{bbm}
vignette: >
  %\VignetteIndexEntry{"IHW-Forest-paper: hQTL analysis with IHW-Benjamini-Yekutieli"}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---


```{r warning=FALSE, message=FALSE}
library(tidyr)
library(IHW)
library(doRNG)
library(doParallel)
library(parallel)
library(fdrtool)
library(ggplot2)
library(cowplot)
theme_set(theme_cowplot())
library(scales)
# library(latex2exp)
library(dplyr)
# require(biomaRt)
set.seed(1)
```

```{r}
error_handler <- function(x) { # TODO
  if (inherits(x, "try-error")) {
    x <- NA
  }
  x
}
```

```{r}
rejections_na <- function(ihw) { # TODO
  if (is.na(ihw)) {
    return(NA)
  } else {
    rejections(ihw)
  }
}
```

```{r setup, include=FALSE, cache = FALSE}
knitr::opts_knit$set(root_dir = "/g/huber/users/fridljand/R/ihw-forest-paper/") # TODO
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
```

```{r hard_coding_path}
# file_loc <- system.file("extdata", "real_data", "hqtl_chrom1_chrom2", package = "IHWpaper")
# file_loc <- "/g/huber/users/fridljand/R/ihw-forest-paper/data/hqtl_chrom1_chrom2/"
root_dir <- "/g/huber/users/fridljand/R/ihw-forest-paper/"
# root_dir <- "/Users/default/Google Drive/currentDocumants/Studium/Master/3.Semester/Masterarbeit/Code/ihw-forest-paper/data/hqtl_chrom1_chrom2/"
# root_dir <- "/Volumes/huber/users/fridljand/R/ihw-forest-paper"
options(bitmapType = "cairo")
```

# Load SNPs and peaks
In this markdown, we apply several multiple testing procedures to the same hQTL analysis as in https://rss.onlinelibrary.wiley.com/doi/10.1111/rssb.12411?af=R, Section 6: APPLICATION EXAMPLE: BIOLOGICAL HIGH-THROUGHPUT DATA. The corresponding vigniette of the old analysis can be found [here](http://bioconductor.org/packages/release/data/experiment/vignettes/IHWpaper/inst/doc/hqtl_IHW_BY.html). In this analysis, the p-values were plotted against the genomic distance and the user had to manually figure out stratification breaks for IHW. Here we want to use the data-driven, automated stratification_methods `"quantile"` and `"forest"`. 


Recall that each hypothesis in an hQTL analysis corresponds to a peak of histone modification (which we call gene below) and a SNP. Hence let us the load files about each of the SNPs 

```{r loading_snp_peak}
snp_chr1 <- readRDS(file.path(root_dir, "data/hqtl_chrom1_chrom2/snppos_chr1.Rds")) %>% dplyr::select(snp, pos)
snp_chr2 <- readRDS(file.path(root_dir, "data/hqtl_chrom1_chrom2/snppos_chr2.Rds")) %>% dplyr::select(snp, pos)
head(snp_chr1)
```

and peaks:
```{r}
all_peaks <- readRDS(file.path(root_dir, "data/hqtl_chrom1_chrom2/peak_locations.Rds"))
peaks_chr1 <- dplyr::filter(all_peaks, chr == "chr1") %>% dplyr::select(id, start, end)
peaks_chr2 <- dplyr::filter(all_peaks, chr == "chr2") %>% dplyr::select(id, start, end)
rm(all_peaks)
head(peaks_chr1)
```

```{r, eval = F, include = F}
range_dist <- c()
pb <- txtProgressBar(min = 0, max = nrow(peaks_chr2), initial = 0)

for (i in 1:nrow(peaks_chr2)) {
  # i <- 1
  setTxtProgressBar(pb, i)
  start_pos <- peaks_chr2$start[i]
  end_pos <- peaks_chr2$end[i]
  dist_vec <- pmin(abs(snp_chr2$pos - start_pos), abs(snp_chr2$pos - end_pos))
  range_dist <- c(range_dist, dist_vec)
  range_dist <- range(range_dist)
}

formatC(range_dist, format = "e", digits = 2)
```

We have pre-calculated the p-values for these hypotheses beforehand, we are going to load now.

```{r loading_pvalues}
chr1_df <- readRDS(file.path(root_dir, "data/hqtl_chrom1_chrom2/chr1_subset.Rds")) %>% dplyr::select(SNP, gene, pvalue)
chr2_df <- readRDS(file.path(root_dir, "data/hqtl_chrom1_chrom2/chr2_subset.Rds")) %>% dplyr::select(SNP, gene, pvalue)
```
Note that only p-values <= 1e-4 are stored in these files to save data storage. For details, how the pvalues are calculated, see [code](https://github.com/nignatiadis/IHWpaper/blob/master/inst/real_data_examples/hqtl_example_analysis.R#L96). 
```{r}
pval_threshold <- 10^(-4)
```

Hence, the censored p-values follow the model 
\begin{eqnarray}
&P_i \mid H_i = 0 \sim U[0,10^(-4)]
\end{eqnarray}

However, all multiple testing used in this vigniette assume 
\begin{eqnarray}
&P_i \mid H_i = 0 \sim U[0,1]
\end{eqnarray}
We address this gap by artificially inflating the p-values:  
```{r}
chr1_df <- chr1_df %>% mutate(pvalue = pvalue / pval_threshold)
chr2_df <- chr2_df %>% mutate(pvalue = pvalue / pval_threshold)
```

# Load covariates
The IHW multiple testing procedure can incorporate additional side information to gain statistical power.

## genomic distance
We calculate the genomic distance between peaks and SNPs for all hypotheses. As [in the original analysis](http://bioconductor.org/packages/release/data/experiment/vignettes/IHWpaper/inst/doc/hqtl_IHW_BY.html), they are going to serve as main covariates for the multiple testing procedure.

```{r}
chr1_df <- left_join(chr1_df, snp_chr1, by = (c("SNP" = "snp"))) %>%
  left_join(peaks_chr1, by = (c("gene" = "id"))) %>%
  transmute(SNP, gene, pvalue, dist = pmin(abs(pos - start), abs(pos - end)))

chr2_df <- left_join(chr2_df, snp_chr2, by = (c("SNP" = "snp"))) %>%
  left_join(peaks_chr2, by = (c("gene" = "id"))) %>%
  transmute(SNP, gene, pvalue, dist = pmin(abs(pos - start), abs(pos - end)))
```

## Minor Allele Frequency
In [here](http://bioconductor.org/packages/release/data/experiment/vignettes/IHWpaper/inst/doc/hqtl_IHW_BY.html) only the genomic distance was used as covariate. Here, we also want to use minor allele frequency (MAF). We load the pre-downloaded MAF file. The data was pre-downloaded with `Biomart`.
```{r, eval = T}
chr1_maf <- readRDS(file = file.path(root_dir, "data/downloaded_covariates/chr1_maf.Rds"))
chr2_maf <- readRDS(file = file.path(root_dir, "data/downloaded_covariates/chr2_maf.Rds"))
```

We annotate the hypotheses with the MAF data.
```{r}
chr1_df <- chr1_df %>% left_join(chr1_maf, by = c("SNP" = "refsnp_id"))
chr2_df <- chr2_df %>% left_join(chr2_maf, by = c("SNP" = "refsnp_id"))
```

Many MAFs are not available on `Biomart`. 
```{r}
chr1_maf_missing <- sum(is.na(chr1_df$minor_allele_freq)) / nrow(chr1_maf)
chr2_maf_missing <- sum(is.na(chr2_df$minor_allele_freq)) / nrow(chr2_maf)

paste0(round(100 * chr1_maf_missing, 2), "%")
paste0(round(100 * chr2_maf_missing, 2), "%")
```

For IHW, missing covariates are not allowed. So we conservatively replace all `NA`s with 0. 
```{r}
chr1_df <- chr1_df %>% mutate(minor_allele_freq = replace_na(minor_allele_freq, 0))
chr2_df <- chr2_df %>% mutate(minor_allele_freq = replace_na(minor_allele_freq, 0))
```

## H3K27Ac, H3K4me3, kH3k4me1, DNAse
Additionally, we source some covariates from the genome browser. For more information on each covariate, please lookup the corresponding track and table on `rtracklayer::trackNames` or on
http://genome.ucsc.edu/cgi-bin/hgTables?org=Human&db=hg19. 
```{r}
readRDS(file.path(root_dir, "data/downloaded_covariates/meta_track_table.Rds"))
```

We mapped the the information to the covariate by taking the closest genomic region.
```{r, eval=TRUE}
chr1_more_cov <- readRDS(file.path(root_dir, "data/downloaded_covariates/snp_chr1_cov_df.Rds"))
chr2_more_cov <- readRDS(file.path(root_dir, "data/downloaded_covariates/snp_chr2_cov_df.Rds"))

names_more_cov <- setdiff(names(chr1_more_cov), c("SNP", "gene"))
chr1_df <- chr1_df %>% left_join(chr1_more_cov, by = c("SNP", "gene"))
chr2_df <- chr2_df %>% left_join(chr2_more_cov, by = c("SNP", "gene"))
```

## Checks

```{r}
any(is.na(chr1_df))
any(is.na(chr2_df))
```


```{r}
chr1_chr2_df <- rbind(chr1_df, chr2_df)
folds_vec <- as.factor(c(rep(1, nrow(chr1_df)), rep(2, nrow(chr2_df))))
rm(chr1_df, chr2_df)
rm(snp_chr1, peaks_chr1, snp_chr2, peaks_chr2)
rm(chr1_maf, chr2_maf)
rm(chr1_more_cov, chr2_more_cov)

chr1_chr2_df <- chr1_chr2_df %>%
  dplyr::select(-one_of(c("SNP")))
```

# Apply IHW-BY and BY
## Run Multiple testing procedures
We want to apply the Benjamini-Yekutieli at alpha=0.1, thus we will apply Benjamini-Hochberg at the corrected level:

```{r}
m <- nrow(chr1_chr2_df)
```

Define formulas
```{r}
formulas_mt <- c(
  "dist",
  "minor_allele_freq",
  "dist + minor_allele_freq",
  paste(c("dist", "minor_allele_freq", names_more_cov), collapse = " + ")#,
  #paste(c("dist", "minor_allele_freq", names_more_cov[endsWith(names_more_cov, "snp")]), collapse = " + ")
)

formulas_mt <- paste0("pvalue ~ ", formulas_mt)
formulas_mt <- sapply(formulas_mt, as.formula)
```

Set effective target FDR (before BY adjustment)
```{r}
alphas <- seq(0.01, 0.1, length.out = 2)#5
```

```{r}
formulas_alpha_levels <- expand.grid(
  formulas = formulas_mt,
  alphas = alphas
)

formulas_alpha_levels <- formulas_alpha_levels %>%
  mutate(
    alphas_by = alphas / (log(m) + 1),
    number_covariates = 1 + stringr::str_count(formulas, "\\+"),
    formula_string = format(formulas)
  )
sapply(formulas_alpha_levels, class)
```

```{r sanity_check}
#formulas_alpha_levels <- formulas_alpha_levels[19:20, ]
head(formulas_alpha_levels)
length(formulas_mt) * length(alphas) == nrow(formulas_alpha_levels)
```

Now let us run IHW with the `"quantile"` stratification method using different subsets of the available covariates:


```{r quantile_rej}
# only rerun, if changes to global variables or code
quantile_rej <- xfun::cache_rds(
  {
    # run for all alpha-formula combinations (in parallel)
    quantile_rej <- foreach(i = 1:nrow(formulas_alpha_levels)) %dorng% {
      print(paste0("simulation run:", i))

      formula_i <- formulas_alpha_levels$formulas[[i]]
      alpha_i <- formulas_alpha_levels$alphas[[i]]
      alphas_by_i <- formulas_alpha_levels$alphas_by[[i]]

      ihw_quantile_i <- error_handler(try(
        ihw(
          formula_i,
          data = chr1_chr2_df,
          alpha = alphas_by_i,
          folds = folds_vec,
          stratification_method = "quantiles"
        )
      ))

      # evaluate number of rejections
      quantile_rej_i <- data.frame(
        method = "IHW-Quantile",
        formula = formulas_alpha_levels$formula_string[i],
        number_covariates = formulas_alpha_levels$number_covariates[i],
        alpha = alpha_i,
        alphas_by = alphas_by_i,
        rejections = rejections_na(ihw_quantile_i)
      )
    }
    quantile_rej <- bind_rows(quantile_rej)
  },
  file = "hqtl_ihw_quantile_rej.rds",
  hash = list(formulas_alpha_levels, chr1_chr2_df)
)

```

Run IHW with the `"forest"` stratification method using different subsets of the available covariates:
```{r hqtl_ihw_forest_rej}
# only rerun, if changes to global variables or code
forest_rej <- xfun::cache_rds(
  {
    # run for all alpha-formula combinations (in parallel)
    forest_rej <- foreach(i = seq_len(nrow(formulas_alpha_levels))) %dorng% {
      print(paste0("run:", i))

      formula_i <- formulas_alpha_levels$formulas[[i]]
      alpha_i <- formulas_alpha_levels$alphas[[i]]
      alphas_by_i <- formulas_alpha_levels$alphas_by[[i]]

      ihw_forest_i <- error_handler(try(
        ihw(
          formula_i,
          data = chr1_chr2_df,
          alpha = alphas_by_i,
          folds = folds_vec,
          stratification_method = "forest",
          n_censor_thres = 1, ntrees = 1, nodedepth = 6, nodesize = 5000
          # n_censor_thres = 5, ntrees = 5, nodedepth = 6, nodesize = 5000 # TODO
        )
      ))
      
      # evaluate number of rejections
      forest_rej_i <- data.frame(
        method = "IHW-Forest",
        formula = formulas_alpha_levels$formula_string[i],
        number_covariates = formulas_alpha_levels$number_covariates[i],
        alpha = alpha_i,
        alphas_by = alphas_by_i,
        rejections = rejections_na(ihw_forest_i)
      )
    }
    forest_rej <- bind_rows(forest_rej)
  },
  file = "hqtl_ihw_forest_rej.rds",
  hash = list(formulas_alpha_levels, chr1_chr2_df)
)
```

Rejections of BY:
```{r by_rej}
# run for all alpha-formula combinations (in parallel)
alpha_levels <- formulas_alpha_levels %>%
  select(alphas, alphas_by) %>%
  distinct()
by_rejections <- foreach(i = seq_len(nrow(alpha_levels))) %dorng% { 
  print(paste0("run:", i))

  alpha_i <- alpha_levels$alphas[[i]]
  alphas_by_i <- alpha_levels$alphas_by[[i]]

  # TODO BH or BY?
  by_rejections_i <- sum(p.adjust(na.exclude(chr1_chr2_df$pvalue), method = "BH") <= alphas_by_i)
  # evaluate number of rejections
  data.frame(
    method = "BY",
    formula = "pvalue ~ 1",
    number_covariates = 0,
    alpha = alpha_i,
    alphas_by = alphas_by_i,
    rejections = by_rejections_i
  )
}
by_rejections <- bind_rows(by_rejections)
```

## Evaluate number of rejections

In the [original analysis](http://bioconductor.org/packages/release/data/experiment/vignettes/IHWpaper/inst/doc/hqtl_IHW_BY.html), where we did not inflate the `pvalue` by the `p_value_threshold`, we had 9110 rejections with BY, so this is very similar.

Rejections of IHW-BY using different stratification methods:

```{r}
result <- bind_rows(by_rejections, quantile_rej, forest_rej)

result <- result %>%
  filter(!is.na(rejections)) %>%
  arrange(alpha, number_covariates, formula, method) 
```



```{r}
result <- result %>%
  mutate(formula_str = ifelse(number_covariates < 4,
                              format(formula),
                              paste("pvalue ~", number_covariates, "covariates")
                              ),
         formula_str = sapply(formula_str, stringr::str_trim),
         formula_str = sapply(formula_str, function(formula_str_i){
           stringr::str_replace(formula_str_i, "minor_allele_freq", "maf")
         }),
         )
```

```{r}
hqtl_rejections <- ggplot(result, aes(x = alpha, y = rejections, col = method)) +
  geom_line() +
  geom_point(size = 2) +
  ylab("Number of rejections") +
  xlab("Target FDR") +
  theme(legend.position="bottom")+
 guides(
  color = guide_legend(title = "Method", legend.text = element_text(size = 4)),
  shape = "none"
 ) +
# scale_x_continuous(breaks = seq(0, 1000, by = 250)) +
 scale_y_log10() +
  facet_wrap(vars(formula_str))+
  scale_x_continuous(breaks = unique(result$alpha)) 
# breaks = c(0.003, 0.01, 0.025, 0.05, 0.1, 0.2, 0.4)
# scale_color_manual(values = c("#00AFBB", "#52854C", "#FC4E07"))
hqtl_rejections
```

```{r}
ggplot2::ggsave("../figures/hqtl_rejections.png", hqtl_rejections,
  width = 6, height = 3.25
)
```

```{r}
hqtl_rejections_by_forest <- result %>% 
  filter(method %in% c("BY", "IHW-Forest")) %>%
ggplot(aes(x = alpha, y = rejections, col = paste(method, formula_str))) +
  geom_line() +
  #geom_point(size = 2) +
  ylab("Number of rejections") +
  xlab("Target FDR") +
  theme(legend.position="bottom")+
  #ggrepel::geom_label_repel(aes(label = paste(method, formula_str)),
  #                nudge_x = 1,
  #                na.rm = TRUE)+
 scale_x_continuous(breaks = unique(result$alpha)) +
 guides(col=guide_legend(nrow=4,byrow=TRUE))+
 scale_y_log10() 
hqtl_rejections_by_forest
```

```{r}
#result$formula_str
hqtl_rejections_quantile_forest <- result %>% 
  filter(method %in% c("IHW-Quantile", "IHW-Forest") &
           formula_str %in% c("pvalue ~ dist", "pvalue ~ 20 covariates")
           #number_covariates <= 2
         ) %>%
ggplot(aes(x = alpha, y = rejections, col = paste(method, formula_str))) +
  geom_line() +
  #geom_point(size = 2) +
  ylab("Number of rejections") +
  xlab("Target FDR") +
  theme(legend.position="bottom")+
  #ggrepel::geom_label_repel(aes(label = paste(method, formula_str)),
  #                nudge_x = 1,
  #                na.rm = TRUE)+
 scale_x_continuous(breaks = unique(result$alpha)) +
 guides(col=guide_legend(nrow=4,byrow=TRUE))+
 scale_y_log10() 
hqtl_rejections_quantile_forest
```

```{r}
ggpubr::ggarrange(hqtl_rejections_by_forest, hqtl_rejections_quantile_forest)

ggplot2::ggsave("../figures/hqtl_rejections_by_forest.png", hqtl_rejections_by_forest,
  width = 6, height = 3.25
)
```

So we see that the number of discoveries has increased in most cases compared to BY. MAF turned out to be not informative, but decreased number of rejections for all stratification methods. However, while IHW-quantile was completely thrown of by an this extra dimension and reduced to classical BY with uniform weights, IHW-Forest was able to handle it.

# Session Info Details
```{r, echo=FALSE, eval=TRUE}
sessionInfo()
```
