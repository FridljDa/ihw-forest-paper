---
title: "hQTL analysis with IHW-Benjamini-Yekutieli"
author: "Danie Fridljand"
date: "`r doc_date()`"
output: BiocStyle::html_document
header-includes:
   - \usepackage{bbm}
vignette: >
  %\VignetteIndexEntry{"IHW-Forest-paper: hQTL analysis with IHW-Benjamini-Yekutieli"}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---


```{r warning=FALSE, message=FALSE}
library(IHW)
library(fdrtool)
library(ggplot2)
library(cowplot)
theme_set(theme_cowplot())
library(tidyr)
library(scales)
library(latex2exp)
library(dplyr)
require(biomaRt)
set.seed(1)
```

```{r setup, include=FALSE, cache = FALSE}
knitr::opts_knit$set(root_dir = "/g/huber/users/fridljand/R/ihw-forest-paper/")
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
```

```{r hard_coding_path}
# file_loc <- system.file("extdata", "real_data", "hqtl_chrom1_chrom2", package = "IHWpaper")
# file_loc <- "/g/huber/users/fridljand/R/ihw-forest-paper/data/hqtl_chrom1_chrom2/"
root_dir <- "/g/huber/users/fridljand/R/ihw-forest-paper/"
# root_dir <- "/Users/default/Google Drive/currentDocumants/Studium/Master/3.Semester/Masterarbeit/Code/ihw-forest-paper/data/hqtl_chrom1_chrom2/"
# root_dir <- "/Volumes/huber/users/fridljand/R/ihw-forest-paper"
options(bitmapType = "cairo")
```

# Load data
In this markdown, we apply several multiple testing procedures to the same hQTL analysis as in https://rss.onlinelibrary.wiley.com/doi/10.1111/rssb.12411?af=R, Section 6: APPLICATION EXAMPLE: BIOLOGICAL HIGH-THROUGHPUT DATA. The corresponding vigniette of the old analysis can be found [here](http://bioconductor.org/packages/release/data/experiment/vignettes/IHWpaper/inst/doc/hqtl_IHW_BY.html). In this analysis, the p-values were plotted against the genomic distance and the user had to manually figure out stratification breaks for IHW. Here we want to use the data-driven, automated stratification_methods `"quantile"` and `"forest"`. 


Recall that each hypothesis in an hQTL analysis corresponds to a peak of histone modification (which we call gene below) and a SNP. Hence let us the load files about each of the SNPs 

```{r loading_snp_peak}
snp_chr1 <- readRDS(file.path(root_dir, "data/hqtl_chrom1_chrom2/snppos_chr1.Rds")) %>% dplyr::select(snp, pos)
snp_chr2 <- readRDS(file.path(root_dir, "data/hqtl_chrom1_chrom2/snppos_chr2.Rds")) %>% dplyr::select(snp, pos)
head(snp_chr1)
```

and peaks:
```{r}
all_peaks <- readRDS(file.path(root_dir, "data/hqtl_chrom1_chrom2/peak_locations.Rds"))
peaks_chr1 <- dplyr::filter(all_peaks, chr == "chr1") %>% dplyr::select(id, start, end)
peaks_chr2 <- dplyr::filter(all_peaks, chr == "chr2") %>% dplyr::select(id, start, end)
rm(all_peaks)
head(peaks_chr1)
```

We have pre-calculated the p-values for these hypotheses beforehand, we are going to load now.

```{r loading_pvalues}
chr1_df <- readRDS(file.path(root_dir, "data/hqtl_chrom1_chrom2/chr1_subset.Rds")) %>% dplyr::select(SNP, gene, pvalue)
chr2_df <- readRDS(file.path(root_dir, "data/hqtl_chrom1_chrom2/chr2_subset.Rds")) %>% dplyr::select(SNP, gene, pvalue)
```
Note that only p-values <= 1e-4 are stored in these. For details, how the pvalues are calculated, see [code](https://github.com/nignatiadis/IHWpaper/blob/master/inst/real_data_examples/hqtl_example_analysis.R). 
```{r}
pval_threshold <- 10^(-4)
```

Hence, the censored p-values follow the model 
\begin{eqnarray}
&P_i \mid H_i = 0 \sim U[0,10^(-4)]
\end{eqnarray}

However, all multiple testing used in this vigniette assume 
\begin{eqnarray}
&P_i \mid H_i = 0 \sim U[0,1]
\end{eqnarray}
We address this gap by artificially inflating the p-values:  
```{r}
chr1_df <- chr1_df %>% mutate(pvalue = pvalue / pval_threshold)
chr2_df <- chr2_df %>% mutate(pvalue = pvalue / pval_threshold)
```

# Covariates
The IHW multiple testing procedure can incorporate additional side information to gain statistical power.

## genomic distance
We now take all cross-combinations between the remaining SNPs and peaks with-in chromosmes. We calculate the genomic distance between peaks and SNPs along the way. As [in the original analysis](http://bioconductor.org/packages/release/data/experiment/vignettes/IHWpaper/inst/doc/hqtl_IHW_BY.html), they are going to serve as main covariates for the multiple testing procedure.

```{r}
chr1_df <- left_join(chr1_df, snp_chr1, by=(c("SNP"="snp"))) %>%
       left_join(peaks_chr1, by=(c("gene"="id"))) %>%
       mutate( dist = pmin(abs(pos-start), abs(pos-end)))

chr2_df <- left_join(chr2_df, snp_chr2, by=(c("SNP"="snp"))) %>%
       left_join(peaks_chr2, by=(c("gene"="id"))) %>%
       mutate( dist = pmin( abs(pos-start), abs(pos-end)))
```

## Minor Allele Frequency
In [here](http://bioconductor.org/packages/release/data/experiment/vignettes/IHWpaper/inst/doc/hqtl_IHW_BY.html) only the genomic distance was used as covariate. Here, we also want to use minor allele frequency (MAF). We load the pre-downloaded MAF file. The data was pre-downloaded with `Biomart`.
```{r, eval = T}
chr1_maf <- readRDS(file = file.path(root_dir, "data/downloaded_covariates/chr1_maf.Rds"))
chr2_maf <- readRDS(file = file.path(root_dir, "data/downloaded_covariates/chr2_maf.Rds"))
```

We annotate the hypotheses with the MAF data.
```{r}
chr1_df <- chr1_df %>% left_join(chr1_maf, by = c("SNP" = "refsnp_id")) 
chr2_df <- chr2_df %>% left_join(chr2_maf, by = c("SNP" = "refsnp_id"))
```

Many MAFs are not available on `Biomart`. 
```{r}
chr1_maf_missing <- sum(is.na(chr1_df$minor_allele_freq))/nrow(chr1_maf)
chr2_maf_missing <- sum(is.na(chr2_df$minor_allele_freq))/nrow(chr2_maf)

paste0(round(100* chr1_maf_missing, 2), "%")
paste0(round(100* chr2_maf_missing, 2), "%")
```

For IHW, missing covariates are not allowed. So we conservatively replace all `NA`s with 0. 
```{r}
chr1_df <- chr1_df %>% mutate(minor_allele_freq = replace_na(minor_allele_freq, 0))
chr2_df <- chr2_df %>% mutate(minor_allele_freq = replace_na(minor_allele_freq, 0))
```

## H3K27Ac, H3K4me3, kH3k4me1, DNAse
```{r, eval=FALSE}
chr1_more_cov <- readRDS(file.path(root_dir, "data/downloaded_covariates/snp_chr1_cov_df.Rds"))
chr2_more_cov <- readRDS(file.path(root_dir, "data/downloaded_covariates/snp_chr2_cov_df.Rds"))

chr1_df <- chr1_df %>% left_join(chr1_more_cov, by = c("SNP" = "SNP")) 
chr2_df <- chr2_df %>% left_join(chr2_more_cov, by = c("SNP" = "SNP"))
```

## Checks

```{r}
any(is.na(chr1_df))
any(is.na(chr2_df))
```


```{r}
chr1_chr2_df <- rbind(chr1_df, chr2_df)
folds_vec <- as.factor(c(rep(1, nrow(chr1_df)), rep(2, nrow(chr2_df))))
rm(chr1_df, chr2_df)
rm(snp_chr1, peaks_chr1, snp_chr2, peaks_chr2)
rm(chr1_maf, chr2_maf)
```

# Apply IHW-BY and BY
## Run Multiple testing procedures
We want to apply the Benjamini-Yekutieli at alpha=0.1, thus we will apply Benjamini-Hochberg at the corrected level:

```{r}
m <- nrow(chr1_chr2_df)
alpha <- .01 / (log(m) + 1)
```

```{r, include=FALSE}
#we do not actually want to calculate all the time
run_write_ihw <- FALSE
```

Now let us run IHW with the `"forest"` stratification method using different subsets of the available covariates:

```{r ihw_quantile_dist, include=TRUE, eval=run_write_ihw}
ihw_quantile_dist <- ihw(pvalue ~ dist, data = chr1_chr2_df, alpha, folds = folds_vec)
```

```{r, include=FALSE, eval=run_write_ihw}
saveRDS(ihw_quantile_dist, file = file.path(root_dir, "precomputed_results/ihw_quantile_dist.Rds"))
```

```{r, include=FALSE, eval=TRUE}
ihw_quantile_dist <- readRDS(file = file.path(root_dir, "precomputed_results/ihw_quantile_dist.Rds"))
```

```{r, eval=FALSE, include=F}
# Run some diagnostics on the `ihw_quantile_dist` object relevant when comparing the stratification methods.
m_groups(ihw_quantile_dist)
stratification_breaks(ihw_quantile_dist)
```

```{r ihw_quantile_maf, eval=run_write_ihw}
ihw_quantile_maf <- ihw(pvalue ~ minor_allele_freq, data = chr1_chr2_df, alpha, folds = folds_vec)
```

```{r, include=FALSE, eval=run_write_ihw}
saveRDS(ihw_quantile_maf, file = file.path(root_dir, "precomputed_results/ihw_quantile_maf.Rds"))
```

```{r, include=FALSE, eval=TRUE}
 ihw_quantile_maf <- readRDS(file = file.path(root_dir, "precomputed_results/ihw_quantile_maf.Rds"))
```

```{r ihw_quantile_dist_maf, eval=run_write_ihw}
ihw_quantile_dist_maf <- ihw(pvalue ~ dist + minor_allele_freq, data = chr1_chr2_df, alpha, folds = folds_vec)
```

```{r, include=FALSE, eval=run_write_ihw}
saveRDS(ihw_quantile_dist_maf, file = file.path(root_dir, "precomputed_results/ihw_quantile_dist_maf.Rds"))
```

```{r, include=FALSE, eval=TRUE}
ihw_quantile_dist_maf <- readRDS(file = file.path(root_dir, "precomputed_results/ihw_quantile_dist_maf.Rds"))
```

```{r, eval = F, include=F}
# Run some diagnostics on the `ihw_quantile_dist_maf` object
weights(ihw_quantile_dist_maf)
```

Run IHW with the `"forest"` stratification method using different subsets of the available covariates:
```{r ihw_forest_dist, eval = run_write_ihw, warning= FALSE}
ihw_forest_dist <- ihw(pvalue ~ dist,
  data = chr1_chr2_df,
  alpha, folds = folds_vec, stratification_method = "forest",
  n_censor_thres = 5, ntrees = 5, nodedepth = 6, nodesize = 5000
)
```

```{r, include=FALSE, eval=run_write_ihw}
saveRDS(ihw_forest_dist, file = file.path(root_dir, "precomputed_results/ihw_forest_dist.Rds"))
```

```{r, include=FALSE, eval=TRUE}
ihw_forest_dist <- readRDS(file = file.path(root_dir, "precomputed_results/ihw_forest_dist.Rds"))
```

```{r, eval = F, include=F}
# run some diagnostics on the `ihw_forest` object
IHW::m_groups(ihw_forest_dist)
stratification_breaks(ihw_forest_dist, fold = 1, tree = 1)
```

```{r ihw_forest_maf, eval = run_write_ihw, warning= FALSE}
ihw_forest_maf <- ihw(pvalue ~ minor_allele_freq,
  data = chr1_chr2_df,
  alpha, folds = folds_vec, stratification_method = "forest",
  n_censor_thres = 5, ntrees = 5, nodedepth = 6, nodesize = 5000
)
```

```{r, include=FALSE, eval=run_write_ihw}
saveRDS(ihw_forest_maf, file = file.path(root_dir, "precomputed_results/ihw_forest_maf.Rds"))
```

```{r, include=FALSE, eval=TRUE}
ihw_forest_maf <- readRDS(file = file.path(root_dir, "precomputed_results/ihw_forest_maf.Rds"))
```

```{r, eval = F, include = F}
list(formula(pvalue ~ dist + minor_allele_freq))
```

```{r ihw_forest_dist_maf, eval = run_write_ihw, warning= FALSE}
ihw_forest_dist_maf <- ihw(pvalue ~ dist + minor_allele_freq,
  data = chr1_chr2_df,
  alpha, folds = folds_vec, stratification_method = "forest",
  n_censor_thres = 5, ntrees = 5, nodedepth = 6, nodesize = 5000
)
```

```{r, include=FALSE, eval=run_write_ihw}
saveRDS(ihw_forest_dist_maf, file = file.path(root_dir, "precomputed_results/ihw_forest_dist_maf.Rds"))
```

```{r, include=FALSE, eval=TRUE}
ihw_forest_dist_maf <- readRDS(file = file.path(root_dir, "precomputed_results/ihw_forest_dist_maf.Rds"))
```

## Evaluate number of rejections
Rejections of BY:

```{r}
sum(p.adjust(na.exclude(chr1_chr2_df$pvalue), method = "BH") <= alpha)
```

Rejections of IHW-BY using different stratification methods:

```{r}
ihw_rejections <- tribble(
  ~formula, ~quantiles, ~forest,
  "pvalue ~ minor_allele_freq", rejections(ihw_quantile_maf), rejections(ihw_forest_maf),
  "pvalue ~ dist", rejections(ihw_quantile_dist), rejections(ihw_forest_dist),
  "pvalue ~ dist + minor_allele_freq", rejections(ihw_quantile_dist_maf), rejections(ihw_forest_dist_maf),
)
as.data.frame(ihw_rejections)
```

So we see that the number of discoveries has increased in most cases compared to BH. MAF turned out to be not informative, but decreased number of rejections for all stratification methods. However, while IHW-quantile was completely thrown of by an this extra dimension and reduced to classical BY with uniform weights, IHW-Forest was able to handle it.

# Session Info Details
```{r, echo=FALSE, eval=TRUE}
sessionInfo()
```
