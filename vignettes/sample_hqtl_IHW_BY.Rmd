---
title: "hQTL analysis with IHW-Benjamini-Yekutieli"
author: "Danie Fridljand"
date: "`r doc_date()`"
output: BiocStyle::html_document
bibliography: bibliography.bib
vignette: >
  %\VignetteIndexEntry{"IHW-Forest-paper: hQTL analysis with IHW-Benjamini-Yekutieli"}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---


```{r warning=FALSE, message=FALSE}
library(dplyr)
library(IHW)
library(fdrtool)
library(ggplot2)
library(cowplot)
theme_set(theme_cowplot())
library(tidyr)
library(scales)
library(latex2exp)
set.seed(1)
```

```{r setup, include=FALSE, cache = FALSE}
knitr::opts_knit$set(root_dir = "/g/huber/users/fridljand/R/ihw-forest-paper/")
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
```


In this markdown, we apply several multiple testing procedures to the same hQTL analysis as in https://rss.onlinelibrary.wiley.com/doi/10.1111/rssb.12411?af=R, Section 6: APPLICATION EXAMPLE: BIOLOGICAL HIGH-THROUGHPUT DATA. The corresponding vigniette of the old analysis can be found [here](http://bioconductor.org/packages/release/data/experiment/vignettes/IHWpaper/inst/doc/hqtl_IHW_BY.html). In this analysis, the p-values were plotted against the genomic distance and the user had to manually figure out stratification breaks for IHW. Here we want to use the data-driven, automated stratification_methods `"quantile"` and `"forest"`. A draw-back of this is, that we would need to load all 1.6 â‹… 10^10 tests to run the same analysis. This is too massive, so we restrict ourselves to the head of the chromosomes for the time-being. The hope is, that it is worth it and we will make more discoveries. Above that, we want to use more covariates but the genomic distance.


```{r}
#file_loc <- system.file("extdata", "real_data", "hqtl_chrom1_chrom2", package = "IHWpaper")
#file_loc <- "/g/huber/users/fridljand/R/ihw-forest-paper/data/hqtl_chrom1_chrom2/"
root_dir <- "/g/huber/users/fridljand/R/ihw-forest-paper/"
# file_loc <- "/Users/default/Google Drive/currentDocumants/Studium/Master/3.Semester/Masterarbeit/Code/ihw-forest-paper/data/hqtl_chrom1_chrom2/"
```

Recall that each hypothesis in an hQTL analysis corresponds to a peak (which we call gene below) and a SNP. Hence let us load files about each of the SNPs and peaks:

```{r}
snp_chr1 <- readRDS(file.path(root_dir, "data/hqtl_chrom1_chrom2/snppos_chr1.Rds")) %>% select(snp, pos)
snp_chr2 <- readRDS(file.path(root_dir, "data/hqtl_chrom1_chrom2/snppos_chr2.Rds")) %>% select(snp, pos)

all_peaks <- readRDS(file.path(root_dir, "data/hqtl_chrom1_chrom2/peak_locations.Rds"))
peaks_chr1 <- dplyr::filter(all_peaks, chr == "chr1") %>% select(id, start, end)
peaks_chr2 <- dplyr::filter(all_peaks, chr == "chr2") %>% select(id, start, end)
rm(all_peaks)
```
We ommit columns, which are not relevant for us right now, because have already pre-calculated the p-values. 
We end up with way fewer hypotheses. We have pre-calculated the p-values for these hypotheses beforehand, we are going to load now.

```{r}
chr1_df <- readRDS(file.path(root_dir, "data/hqtl_chrom1_chrom2/chr1_subset.Rds")) %>% select(SNP, gene, pvalue)
chr2_df <- readRDS(file.path(root_dir, "data/hqtl_chrom1_chrom2/chr2_subset.Rds")) %>% select(SNP, gene, pvalue)
```
Note that only p-values <= 1e-4 are stored in these. For details, how the pvalues are calculated, see [code](https://github.com/nignatiadis/IHWpaper/blob/master/inst/real_data_examples/hqtl_example_analysis.R). 
```{r}
pval_threshold <- 10^(-4)
```

In the hQTL analysis, we test all possible combinations between peaks and SNPs within a chromosome, e.g.
```{r}
paste(nrow(snp_chr1),"*", nrow(peaks_chr1), "+", nrow(snp_chr2),"*", nrow(peaks_chr2))
```
 
The full analysis has 15.725.016.812 = 16 billion hypotheses. This is too massive. To get some progress, we need to sub-sample it. We are aware, that the below sub-sampling is biased. `chr1_df` only contains only p-values <= 1e-4 are stored in these. We will revisit this later.
```{r, eval = F, include=F}
snp_chr1 <- snp_chr1[1:50, ]
snp_chr2 <- snp_chr2[1:50, ]

peaks_chr1 <- peaks_chr1[1:100, ]
peaks_chr2 <- peaks_chr2[1:100, ]
```

```{r, eval = T, include=T}
chr1_df <- chr1_df %>% slice(1000) #slice_sample(n = 1000)
chr2_df <- chr2_df %>% slice(1000) #slice_sample(n = 1000)

peaks_chr1 <- peaks_chr1 %>% filter(id %in% chr1_df$gene)
peaks_chr2 <- peaks_chr2 %>% filter(id %in% chr2_df$gene)

snp_chr1 <- snp_chr1 %>% filter(snp %in% chr1_df$SNP)
snp_chr2 <- snp_chr2 %>% filter(snp %in% chr2_df$SNP)
```

```{r}
range(snp_chr1$pos)
range(snp_chr2$pos)

c(min(peaks_chr1$start), min(peaks_chr1$end))
c(min(peaks_chr2$start), min(peaks_chr2$end))
```

We now take all cross-combinations between the remaining SNPs and peaks with-in chromosmes. We calculate the genomic distance between peaks and SNPs along the way. As [here](http://bioconductor.org/packages/release/data/experiment/vignettes/IHWpaper/inst/doc/hqtl_IHW_BY.html), they are going to serve as main covariate.
```{r}
full_comb_chr1 <- full_join(snp_chr1, peaks_chr1, by = character()) %>%
  transmute(snp, id,
    dist = pmin(abs(pos - start), abs(pos - end))
  )

full_comb_chr2 <- full_join(snp_chr2, peaks_chr2, by = character()) %>%
  transmute(snp, id,
    dist = pmin(abs(pos - start), abs(pos - end))
  )
nrow(full_comb_chr1) + nrow(full_comb_chr2)
```

We add the pre-calculated p-values to the hypotheses with. For the internal optimization parameter `m_groups` of the weights in IHW all p-values need to be specified. So we set all missing p-values (e.g. p-values >= 1e-4) to 1. This crude rounding will not affect Benjamini-Hochberg at all and ideally IHW not too much. Note that AdaPT, a competing multiple testing method based on covariates, depends on the precise large p-values to estimate the FDR and hence could not be applied here.
```{r}
chr1_df <- full_comb_chr1 %>%
  left_join(chr1_df, by = (c("snp" = "SNP", "id" = "gene"))) %>%
  transmute(dist, pvalue = replace_na(pvalue, 1))

chr2_df <- full_comb_chr2 %>%
  left_join(chr2_df, by = (c("snp" = "SNP", "id" = "gene"))) %>%
  transmute(dist, pvalue = replace_na(pvalue, 1))
```

We also want to use minor allele frequency (MAF) as covariate. 
```{r}
chr1_maf <- readRDS(file = file.path(root_dir, "data/downloaded_covariates/chr1_maf.Rds"))
chr2_maf <- readRDS(file = file.path(root_dir, "data/downloaded_covariates/chr2_maf.Rds"))
```
Again, no na-values allowed. 
```{r}
chr1_maf <- chr1_maf %>% mutate(minor_allele_freq = replace_na(minor_allele_freq, 0))
chr2_maf <- chr2_maf %>% mutate(minor_allele_freq = replace_na(minor_allele_freq, 0))
```

```{r}
chr1_df <- chr1_df %>% left_join(chr1_maf, by = (c("SNP" = "refsnp_id")))
chr2_df <- chr2_df %>% left_join(chr2_maf, by = (c("SNP" = "refsnp_id")))
```

We double check, that number of total hypotheses works out.

```{r}
m <- nrow(peaks_chr1) * nrow(snp_chr1) + nrow(snp_chr2) * nrow(peaks_chr2)
m == nrow(chr1_df) + nrow(chr2_df)
m == nrow(full_comb_chr1) + nrow(full_comb_chr2)
m
any(is.na(chr1_df))
any(is.na(chr2_df))
```

Let us put the data for the two chromosomes together:

```{r}
chr1_chr2_df <- rbind(chr1_df, chr2_df)
# folds_vec <- as.factor(c(rep(1, nrow(chr1_df)), rep(2, nrow(chr2_df))))
folds_vec <- c(rep(factor(1), nrow(chr1_df)), rep(factor(2), nrow(chr2_df)))
rm(chr1_df, chr2_df)
rm(snp_chr1, peaks_chr1, snp_chr2, peaks_chr2, full_comb_chr1, full_comb_chr2)
```

# Apply IHW-BY and BY

We want to apply the Benjamini-Yekutieli at alpha=0.1, thus we will apply Benjamini-Hochberg at the corrected level:

```{r}
alpha <- .01 / (log(m) + 1)
```

Lets extract the covariate columns into one matrix
```{r}
chr1_chr2_cov <- chr1_chr2_df %>% 
  select(dist, minor_allele_freq) %>%
  as.matrix()
```

Now let us run the IHW procedure:
```{r}
ihw_quantile <- ihw(chr1_chr2_df$pvalue, chr1_chr2_cov, alpha, folds = folds_vec)
```
run some diagnostics
```{r, eval = F}
m_groups(ihw_quantile)
stratification_breaks(ihw_quantile)
```

```{r, eval = T}
ihw_forest <- ihw(chr1_chr2_df$pvalue, chr1_chr2_cov, alpha,
  folds = folds_vec, stratification_method = "forest",
  n_censor_thres = 2, ntrees = 1, nodedepth = 5, nodesize = 1000
)
```
run some diagnostics
```{r, eval = F}
IHW::m_groups(ihw_forest)
stratification_breaks(ihw_forest, fold = 1, tree = 1)
```

Rejections of BY:

```{r}
sum(p.adjust(na.exclude(chr1_chr2_df$pvalue), n = m, method = "BH") <= alpha)
```

Rejections of IHW-BY-quantile:

```{r}
rejections(ihw_quantile)
```
Rejections of IHW-BY-forest:

```{r}
rejections(ihw_forest)
```

# Session Info Details
```{r, echo=FALSE, eval=TRUE}
sessionInfo()
```
