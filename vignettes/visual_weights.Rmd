---
title: "IHW visualise weights"
output: html_document
---


Loading packages.
```{r setup, message = F}
library(magrittr)
library(dplyr)
library(ggplot2)
library(IHW)
knitr::opts_chunk$set(echo = TRUE)
set.seed(1234)
theme_set(theme_bw())
```

Generate simulation from https://support.bioconductor.org/p/90005/#9137847. 
```{r}
# test data
m_test <- 100
m <- 1e5
# nfolds <- 3
# folds <- sample(1:nfolds, m, replace = TRUE)
```

```{r}
prop_alt <- function(cov1, cov2) {
  1 / (1 + exp(-cov1))
  # 1 / (1 + exp(-1 * (3 * cov1 - 5)))
  # abs(sin(pi*cov1))
}
```

```{r}
data_train <- data.frame(
  cov1 = runif(m, -1, 1),
  cov2 = runif(m, -1, 1)
)

data_train <- data_train %>%
  mutate(
    prop_alt = prop_alt(cov1, cov2),
    Hs = rbinom(n(), size = 1, prop_alt),
    pvalue = ifelse(Hs,
      rbeta(n(), 0.25, 1),
      runif(n())
    )
  )

data_test <- expand.grid(
  cov1 = seq(-1, 1, length.out = m_test),
  cov2 = seq(-1, 1, length.out = m_test)
)

data_test <- data_test %>% mutate(
  prop_alt = prop_alt(cov1, cov2),
  Hs = rbinom(n(), size = 1, prop_alt),
  pvalue = ifelse(Hs,
    rbeta(n(), 0.25, 1),
    runif(n())
  )
)
```

```{r}
data_true <- expand.grid(
  cov1 = seq(-1, 1, length.out = m_test),
  cov2 = seq(-1, 1, length.out = m_test)
)

data_true <- data_true %>%
  mutate(
    prop_alt = prop_alt(cov1, cov2),
    true_alt_expectation = 0.25 / (0.25 + 1),
    cond_exp = 0.5 + prop_alt * (0.5 - true_alt_expectation),
  )
```

Benjamini Hochberg:
```{r}
rjs_bh <- p.adjust(data_train$pvalue, n = nrow(data_train), method = "BH") <= 0.1
sum(rjs_bh)
```

parameters:
```{r}
nbins <- 9
```

Quantile slicing:
```{r, eval = T}
covariate_train <- as.matrix(select(data_train, starts_with("cov")))

set.seed(0)
ihw_quantile <- ihw(data_train$pvalue, covariate_train, alpha = 0.1, nbins = nbins)

rjs_quantile <- IHW::rejected_hypotheses(ihw_quantile)
sum(rjs_quantile)
```
Set parameters for forest
```{r}
n_censor_thres <- 2
ntrees <- 1
nodedepth <- 3
nodesize <- 1500
```

```{r}
set.seed(0)
ihw_forest <- ihw(data_train$pvalue, covariate_train,
  alpha = 0.1, stratification_method = "forest",
  n_censor_thres = n_censor_thres, ntrees = ntrees, nodedepth = nodedepth, nodesize = nodesize
)
rjs_forest <- IHW::rejected_hypotheses(ihw_forest)
sum(rjs_forest)
```

```{r}
fdp_eval <- function(Hs, rjs) {
  rjs_total <- sum(rjs)
  correct_rej <- sum(rjs * Hs)
  pow <- sum(rjs * Hs) / max(1, sum(Hs))
  FDP <- sum(rjs * (1 - Hs)) / max(1, rjs_total)
  data.frame(rjs = rjs_total, pow = pow, correct_rej = correct_rej, FDP = FDP)
}
```


```{r, eval = T}
evaluated_bh <- fdp_eval(Hs = data_train$Hs, rjs = rjs_bh)
evaluated_quantile <- fdp_eval(Hs = data_train$Hs, rjs = rjs_quantile)
evaluated_forest <- fdp_eval(Hs = data_train$Hs, rjs = rjs_forest)
rbind(
  evaluated_bh,
  evaluated_quantile,
  evaluated_forest
)
evaluated_quantile$pow < evaluated_forest$pow
```

```{r}
groups_cut <- groups_by_filter_multivariate(select(data_test, starts_with("cov")), nbins)

data_cut <- cbind(data_test, groups_cut)

data_cut <- data_cut %>%
  group_by(groups_cut) %>%
  mutate(ecdf = 1 - mean(pvalue)) %>%
  ungroup()

data_cut <- data_cut %>%
  group_by(cov1, cov2) %>%
  summarize(ecdf = mean(ecdf)) %>%
  ungroup()
```

```{r, eval = T}
data_train_test <- rbind(data_train, data_test)
folds <- c(rep(1, nrow(data_train)), rep(2, nrow(data_test)))
```

```{r}
groups_forest <- group_by_forest(data_train_test$pvalue, select(data_train_test, starts_with("cov")), folds,
  n_censor_thres = n_censor_thres, ntrees = ntrees, nodedepth = nodedepth, nodesize = nodesize
)
groups_forest_test <- groups_forest[[2]]

data_forest <- cbind(data_test, groups_forest_test)

data_forest <- data_forest %>%
  tidyr::pivot_longer(
    starts_with("fold"),
    names_to = "tree",
    values_to = "tree_group"
  )

data_forest <- data_forest %>%
  group_by(tree, tree_group) %>%
  mutate(ecdf = 1 - mean(pvalue)) %>%
  ungroup()
```

cherry picking
```{r, eval = F}
plots_forest_simpl <- lapply(names(groups_forest), function(group_i) {
  data_forest_simpl_i <- data_forest %>%
    filter(tree == group_i) %>% # group1 looks best
    group_by(cov1, cov2) %>%
    summarize(ecdf = mean(ecdf)) %>%
    ungroup()

  data_forest_simpl_i %>%
    ggplot(aes(cov1, cov2, color = ecdf)) +
    geom_point()
})

ggsave("~/R/IHW-1/figures/arrange2x2.pdf", gridExtra::marrangeGrob(grobs = plots_forest_simpl, nrow = 2, ncol = 2),
  device = "pdf"
)
```

```{r}
data_forest_simpl <- data_forest %>%
  filter(tree == "fold2_17%_tree1") %>% # group1 looks best
  group_by(cov1, cov2) %>%
  summarize(ecdf = mean(ecdf)) %>%
  ungroup()

data_forest <- data_forest %>%
  group_by(cov1, cov2) %>%
  summarize(ecdf = mean(ecdf)) %>%
  ungroup()
```

```{r}
limits <- c(min(c(data_true$cond_exp, data_cut$ecdf, data_forest_simpl$ecdf, data_forest$ecdf)), max(c(data_true$cond_exp, data_cut$ecdf, data_forest_simpl$ecdf, data_forest$ecdf)))
```

```{r}
myPalette <- colorRampPalette(rev(RColorBrewer::brewer.pal(11, "Spectral")))
# range(data_true$cond_exp)
g1 <- data_true %>%
  ggplot(aes(cov1, cov2, color = cond_exp)) +
  geom_point() +
  scale_colour_gradientn(colours = myPalette(100), limits = limits) +
  labs(color = "Conditional Expectation") +
  ggtitle("True model")
```

```{r}
g2 <- data_cut %>%
  ggplot(aes(cov1, cov2, color = ecdf)) +
  geom_point() +
  scale_colour_gradientn(colours = myPalette(100), limits = limits) +
  ggtitle("Quantile slicing")
```

```{r}
g3 <- data_forest_simpl %>%
  ggplot(aes(cov1, cov2, color = ecdf)) +
  geom_point() +
  scale_colour_gradientn(colours = myPalette(100), limits = limits) +
  ggtitle("Boca Leek single Tree")
```
much more nuanced.
```{r, eval = T}
g4 <- data_forest %>%
  ggplot(aes(cov1, cov2, color = ecdf)) +
  geom_point() +
  scale_colour_gradientn(colours = myPalette(100), limits = limits) +
  ggtitle("Boca Leek Forest (T=100)")
```

```{r}
g_combined <- ggpubr::ggarrange(g1, g2, g3, g4, ncol = 2, nrow = 2, common.legend = TRUE, legend = "bottom")

ggplot2::ggsave("../figures/visual_weights.png", g_combined,
  width = 5, height = 3.25
)

g_combined
```

```{r, eval = F}
width <- 5 / 2 * 1.25
height <- 3.75 / 2 * 1.25
g2 <- g2 +
  ggtitle(NULL) +
  theme(legend.position = "none") +
  xlab("") +
  ylab("covariate 2")

g3 <- g3 +
  ggtitle(NULL) +
  theme(legend.position = "none") +
  xlab("") +
  ylab("covariate 2")

g4 <- g4 +
  ggtitle(NULL) +
  theme(legend.position = "none") +
  xlab("covariate 1") +
  ylab("covariate 2")
#ggplot2::ggsave("~/R/IHW-1/figures/g4.png", g4,
#  width = width, height = height
#)
```

main take aways:
it prioritizes more informative covariates
extreme case: it can ignore irrelevant covariates
random forest => smoother, more steps, without violating the optimization constraint
can capture variation better
sensitive to small regions => we want to assign high priority those
quantile slicing does not extend to high dimensional covariates at all, because of exponential increase
quantile slicing only depends on covariates, not p-values
